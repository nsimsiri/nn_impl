{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import sklearn.datasets as sk_data\n",
    "import math\n",
    "import time\n",
    "#d afdsf\n",
    "mnist = fetch_mldata('MNIST original', data_home=sk_data.get_data_home())\n",
    "\n",
    "IMG_PIX = mnist.data.shape[1]\n",
    "IMG_SIZE = int(math.sqrt(IMG_PIX))\n",
    "TRAINING_SIZE = 60000\n",
    "TEST_SIZE = 10000\n",
    "TOTAL_SIZE = mnist.data.shape[0]\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 100\n",
    "WINDOW_SIZE = 10000/BATCH_SIZE\n",
    "\n",
    "print \"IMG_PIX: %s\\nIMG_SIZE: %s\\nTOTAL_SIZE: %s\\n\"%(IMG_PIX, IMG_SIZE, TOTAL_SIZE)\n",
    "\n",
    "def vectorize_y(Y):\n",
    "    v_y = np.zeros((Y.shape[0], max(set(Y.flatten()))+1))\n",
    "    print v_y.shape\n",
    "    for i in range(len(Y)):\n",
    "        v_y[i][Y[i]] = 1.0\n",
    "    return v_y\n",
    "\n",
    "def shuffle(X, Y):\n",
    "    Y = np.array([Y.flatten()]).T\n",
    "    A = np.concatenate((X, Y),axis=1)\n",
    "    np.random.shuffle(A)\n",
    "    X_prime, Y_prime = np.hsplit(A, [-1])\n",
    "#     if (set(Y_prime.flatten())!=set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])):\n",
    "#         return shuffle(X,Y)\n",
    "    Y_prime = Y_prime.reshape(Y_prime.shape[0],)\n",
    "    return X_prime, Y_prime\n",
    "\n",
    "def prepare_data(_mnist):\n",
    "    _mnist.data = _mnist.data.astype(np.float32)\n",
    "    _mnist.data = np.multiply(_mnist.data, 1.0 / 255.0)\n",
    "    _mnist.target = _mnist.target.astype(np.uint8)\n",
    "    train_xx, test_xx = np.vsplit(_mnist.data, [TRAINING_SIZE])\n",
    "    train_yy, test_yy = np.array_split(_mnist.target, [TRAINING_SIZE])\n",
    "    return train_xx, test_xx, train_yy, test_yy\n",
    "\n",
    "print type(mnist.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fftf\n",
    "import ffbn\n",
    "\n",
    "HIDDEN_1 = 64\n",
    "HIDDEN_2 = 64\n",
    "ALPHA = 0.5\n",
    "USING_BATCH_NORM = False\n",
    "if (USING_BATCH_NORM):\n",
    "    import ffbn as ff\n",
    "else: \n",
    "    import fftf as ff\n",
    "\n",
    "train_x, test_x, train_y, test_y = prepare_data(mnist)\n",
    "print \"training =>\", train_x.shape, train_y.shape\n",
    "print \"testing =>\", test_x.shape, test_y.shape\n",
    "print ff\n",
    "\n",
    "with tf.Graph().as_default(), tf.device('/gpu:0'):      \n",
    "    img_input = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMG_PIX])\n",
    "    label_input = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\n",
    "    model = None\n",
    "    if (USING_BATCH_NORM):\n",
    "        model = ff.inference(img_input, HIDDEN_1, HIDDEN_2, batch_norm_ver=None)\n",
    "    else:\n",
    "        model = ff.inference(img_input, HIDDEN_1, HIDDEN_2)\n",
    "    loss_f = ff.loss(model, label_input)\n",
    "    training_model = ff.training(loss_f, ALPHA)\n",
    "    eval_f = ff.evaluation(model, label_input)\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    loss_arr = []\n",
    "    eval_arr = []\n",
    "    moving_done = False\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as sess:\n",
    "        sess.run(init)\n",
    "        t0 = time.time()\n",
    "        moving_idx = 0\n",
    "        moving_avg = np.zeros(WINDOW_SIZE)\n",
    "        step = 0\n",
    "        for i in xrange(EPOCH):\n",
    "            print \"EPOCH:\", i+1\n",
    "            acc_sum = 0\n",
    "            train_x, train_y = shuffle(train_x, train_y)\n",
    "            for j in xrange(0, TRAINING_SIZE, BATCH_SIZE):\n",
    "                train_x_batch = train_x[j:j+BATCH_SIZE]\n",
    "                train_y_batch = train_y[j:j+BATCH_SIZE]\n",
    "                _, loss, correct = sess.run([training_model, loss_f, eval_f], feed_dict={\n",
    "                    img_input: train_x_batch,\n",
    "                    label_input: train_y_batch\n",
    "                })\n",
    "                \n",
    "                moving_avg[moving_idx] = correct/len(train_x_batch)\n",
    "                moving_idx += 1\n",
    "                if (moving_idx >= WINDOW_SIZE):\n",
    "                    moving_idx = 0\n",
    "                    moving_done = True\n",
    "                \n",
    "                wind_avg= moving_avg.sum()/WINDOW_SIZE\n",
    "                \n",
    "                if(j%1000)==0 or j+BATCH_SIZE == TRAINING_SIZE:\n",
    "                    print \"(STEP %s) loss= %s acc= %s accum_acc= %s t= %s sec\"%(step, loss, correct/BATCH_SIZE, wind_avg, time.time()-t0)\n",
    "                \n",
    "                if (moving_done and wind_avg >= 0.97):\n",
    "                    print \"-----------------\"\n",
    "                    print \"(STEP %s) loss= %s acc= %s accum_acc= %s t= %s sec\"%(step, loss, correct/BATCH_SIZE, wind_avg, time.time()-t0)\n",
    "                    done = True\n",
    "                    break;\n",
    "                step+=1\n",
    "                    \n",
    "            if (done):\n",
    "                break;\n",
    "        num_correct = 0\n",
    "        for k in xrange(0, TEST_SIZE, BATCH_SIZE):\n",
    "            eval_x, eval_y = test_x[k:k+BATCH_SIZE], test_y[k:k+BATCH_SIZE]\n",
    "            if (len(eval_x)!=BATCH_SIZE): \n",
    "                break\n",
    "            correct = sess.run(eval_f, feed_dict={\n",
    "                img_input: eval_x,\n",
    "                label_input: eval_y\n",
    "            })\n",
    "            num_correct += correct\n",
    "#                 print num_correct, correct\n",
    "        print \"\\tTEST ACCURACY= %s\"%(num_correct/TEST_SIZE)\n",
    "                    \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "# ds = input_data.read_data_sets(\"data\", validation_size=0)\n",
    "\n",
    "# print ds.train.epochs_completed\n",
    "# print ds.train.images.shape\n",
    "\n",
    "# print train_y[0]==ds.train.labels[1]\n",
    "# print set(ds.train.images[1]) == set(train_x[0])\n",
    "\n",
    "# plt.subplot(3,3,1)\n",
    "# plt.imshow(train_x[0].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,2)\n",
    "# plt.imshow(train_x[1].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,3)\n",
    "# plt.imshow(train_x[2].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,4)\n",
    "# plt.imshow(train_x[3].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,5)\n",
    "# plt.imshow(train_x[4].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,6)\n",
    "# plt.imshow(train_x[5].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,7)\n",
    "# plt.imshow(train_x[6].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,8)\n",
    "# plt.imshow(train_x[7].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,9)\n",
    "# plt.imshow(train_x[8].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "# # plt.subplot(1,2,2)\n",
    "# # plt.imshow(ds.train.images[3].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# # print train_y[2]\n",
    "# # print ds.train.labels[3]\n",
    "\n",
    "# print type(ds.train.labels[0])\n",
    "# print train_y[:10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=80\n",
    "import time\n",
    "with tf.Graph().as_default(), tf.device('/gpu:0'):\n",
    "    a = tf.truncated_normal([n,n])\n",
    "    b = tf.truncated_normal([n,n])\n",
    "    c = tf.matmul(a,b)\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    t0 = time.time()\n",
    "    sess.run(c)\n",
    "    print(time.time()-t0)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
