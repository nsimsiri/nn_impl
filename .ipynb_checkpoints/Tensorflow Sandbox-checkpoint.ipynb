{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NatchaS/anaconda/envs/tensorflow/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_PIX: 784\n",
      "IMG_SIZE: 28\n",
      "TOTAL_SIZE: 70000\n",
      "\n",
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import sklearn.datasets as sk_data\n",
    "import math\n",
    "import time\n",
    "\n",
    "mnist = fetch_mldata('MNIST original', data_home=sk_data.get_data_home())\n",
    "\n",
    "IMG_PIX = mnist.data.shape[1]\n",
    "IMG_SIZE = int(math.sqrt(IMG_PIX))\n",
    "TRAINING_SIZE = 60000\n",
    "TEST_SIZE = 10000\n",
    "TOTAL_SIZE = mnist.data.shape[0]\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 100\n",
    "WINDOW_SIZE = 10000/BATCH_SIZE\n",
    "\n",
    "print \"IMG_PIX: %s\\nIMG_SIZE: %s\\nTOTAL_SIZE: %s\\n\"%(IMG_PIX, IMG_SIZE, TOTAL_SIZE)\n",
    "\n",
    "def vectorize_y(Y):\n",
    "    v_y = np.zeros((Y.shape[0], max(set(Y.flatten()))+1))\n",
    "    print v_y.shape\n",
    "    for i in range(len(Y)):\n",
    "        v_y[i][Y[i]] = 1.0\n",
    "    return v_y\n",
    "\n",
    "def shuffle(X, Y):\n",
    "    Y = np.array([Y.flatten()]).T\n",
    "    A = np.concatenate((X, Y),axis=1)\n",
    "    np.random.shuffle(A)\n",
    "    X_prime, Y_prime = np.hsplit(A, [-1])\n",
    "#     if (set(Y_prime.flatten())!=set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])):\n",
    "#         return shuffle(X,Y)\n",
    "    Y_prime = Y_prime.reshape(Y_prime.shape[0],)\n",
    "    return X_prime, Y_prime\n",
    "\n",
    "def prepare_data(_mnist):\n",
    "    _mnist.data = _mnist.data.astype(np.float32)\n",
    "    _mnist.data = np.multiply(_mnist.data, 1.0 / 255.0)\n",
    "    _mnist.target = _mnist.target.astype(np.uint8)\n",
    "    train_xx, test_xx = np.vsplit(_mnist.data, [TRAINING_SIZE])\n",
    "    train_yy, test_yy = np.array_split(_mnist.target, [TRAINING_SIZE])\n",
    "    return train_xx, test_xx, train_yy, test_yy\n",
    "\n",
    "print type(mnist.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training => (60000, 784) (60000,)\n",
      "testing => (10000, 784) (10000,)\n",
      "<module 'fftf' from 'fftf.pyc'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NatchaS/anaconda/envs/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:41: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "(STEP 0) loss= 2.32018 acc= 0.05 accum_acc= 0.0005 t= 0.47359585762 sec\n",
      "(STEP 10) loss= 2.31344 acc= 0.06 accum_acc= 0.0089 t= 0.503039836884 sec\n",
      "(STEP 20) loss= 2.3047 acc= 0.1 accum_acc= 0.0184 t= 0.53270483017 sec\n",
      "(STEP 30) loss= 2.31537 acc= 0.04 accum_acc= 0.0271 t= 0.566677808762 sec\n",
      "(STEP 40) loss= 2.31 acc= 0.09 accum_acc= 0.036 t= 0.596077919006 sec\n",
      "(STEP 50) loss= 2.27036 acc= 0.18 accum_acc= 0.048 t= 0.625663995743 sec\n",
      "(STEP 60) loss= 2.28053 acc= 0.15 accum_acc= 0.0598 t= 0.655689954758 sec\n",
      "(STEP 70) loss= 2.26653 acc= 0.13 accum_acc= 0.0728 t= 0.690178871155 sec\n",
      "(STEP 80) loss= 2.26153 acc= 0.17 accum_acc= 0.0877 t= 0.757141828537 sec\n",
      "(STEP 90) loss= 2.26294 acc= 0.13 accum_acc= 0.1042 t= 0.812376976013 sec\n",
      "(STEP 100) loss= 2.2552 acc= 0.22 accum_acc= 0.1233 t= 0.844218015671 sec\n",
      "(STEP 110) loss= 2.25275 acc= 0.2 accum_acc= 0.1366 t= 0.876030921936 sec\n",
      "(STEP 120) loss= 2.25904 acc= 0.23 accum_acc= 0.1485 t= 0.910452842712 sec\n",
      "(STEP 130) loss= 2.23515 acc= 0.23 accum_acc= 0.1649 t= 1.00139188766 sec\n",
      "(STEP 140) loss= 2.23075 acc= 0.27 accum_acc= 0.1852 t= 1.04334282875 sec\n",
      "(STEP 150) loss= 2.24619 acc= 0.21 accum_acc= 0.2021 t= 1.08197379112 sec\n",
      "(STEP 160) loss= 2.21058 acc= 0.27 accum_acc= 0.2218 t= 1.12484383583 sec\n",
      "(STEP 170) loss= 2.20538 acc= 0.37 accum_acc= 0.2414 t= 1.17981386185 sec\n",
      "(STEP 180) loss= 2.20463 acc= 0.28 accum_acc= 0.2623 t= 1.21579480171 sec\n",
      "(STEP 190) loss= 2.20575 acc= 0.31 accum_acc= 0.2828 t= 1.24944281578 sec\n",
      "(STEP 200) loss= 2.18601 acc= 0.37 accum_acc= 0.3027 t= 1.28170895576 sec\n",
      "(STEP 210) loss= 2.16109 acc= 0.34 accum_acc= 0.3205 t= 1.3186519146 sec\n",
      "(STEP 220) loss= 2.15071 acc= 0.42 accum_acc= 0.3388 t= 1.3608109951 sec\n",
      "(STEP 230) loss= 2.14186 acc= 0.43 accum_acc= 0.3572 t= 1.42517399788 sec\n",
      "(STEP 240) loss= 2.14625 acc= 0.47 accum_acc= 0.3716 t= 1.47130894661 sec\n",
      "(STEP 250) loss= 2.14543 acc= 0.45 accum_acc= 0.389 t= 1.50092887878 sec\n",
      "(STEP 260) loss= 2.11285 acc= 0.46 accum_acc= 0.4036 t= 1.53074979782 sec\n",
      "(STEP 270) loss= 2.12508 acc= 0.44 accum_acc= 0.4188 t= 1.56532096863 sec\n",
      "(STEP 280) loss= 2.081 acc= 0.52 accum_acc= 0.4303 t= 1.63592290878 sec\n",
      "(STEP 290) loss= 2.09319 acc= 0.51 accum_acc= 0.4449 t= 1.66706800461 sec\n",
      "(STEP 300) loss= 2.04676 acc= 0.61 accum_acc= 0.4595 t= 1.6968228817 sec\n",
      "(STEP 310) loss= 2.04499 acc= 0.61 accum_acc= 0.4756 t= 1.72692799568 sec\n",
      "(STEP 320) loss= 2.06091 acc= 0.47 accum_acc= 0.4862 t= 1.75707387924 sec\n",
      "(STEP 330) loss= 2.04101 acc= 0.66 accum_acc= 0.5036 t= 1.79355883598 sec\n",
      "(STEP 340) loss= 2.02127 acc= 0.59 accum_acc= 0.5182 t= 1.88122987747 sec\n",
      "(STEP 350) loss= 1.98927 acc= 0.65 accum_acc= 0.5303 t= 1.92312693596 sec\n",
      "(STEP 360) loss= 1.94653 acc= 0.62 accum_acc= 0.5419 t= 1.95453190804 sec\n",
      "(STEP 370) loss= 1.94726 acc= 0.61 accum_acc= 0.5543 t= 1.98377895355 sec\n",
      "(STEP 380) loss= 1.97507 acc= 0.59 accum_acc= 0.5652 t= 2.02060198784 sec\n",
      "(STEP 390) loss= 1.96552 acc= 0.63 accum_acc= 0.5717 t= 2.08098578453 sec\n",
      "(STEP 400) loss= 1.94213 acc= 0.63 accum_acc= 0.5797 t= 2.17566394806 sec\n",
      "(STEP 410) loss= 1.9758 acc= 0.6 accum_acc= 0.5865 t= 2.24827480316 sec\n",
      "(STEP 420) loss= 1.94275 acc= 0.6 accum_acc= 0.5981 t= 2.36108994484 sec\n",
      "(STEP 430) loss= 1.86998 acc= 0.57 accum_acc= 0.5983 t= 2.39288878441 sec\n",
      "(STEP 440) loss= 1.86889 acc= 0.64 accum_acc= 0.6072 t= 2.4225358963 sec\n",
      "(STEP 450) loss= 1.91619 acc= 0.61 accum_acc= 0.6139 t= 2.45441889763 sec\n",
      "(STEP 460) loss= 1.85908 acc= 0.64 accum_acc= 0.6211 t= 2.50534582138 sec\n",
      "(STEP 470) loss= 1.822 acc= 0.7 accum_acc= 0.6288 t= 2.60096883774 sec\n",
      "(STEP 480) loss= 1.86365 acc= 0.61 accum_acc= 0.6341 t= 2.66625499725 sec\n",
      "(STEP 490) loss= 1.81972 acc= 0.65 accum_acc= 0.6426 t= 2.75189590454 sec\n",
      "(STEP 500) loss= 1.79019 acc= 0.69 accum_acc= 0.6477 t= 2.81266379356 sec\n",
      "(STEP 510) loss= 1.74432 acc= 0.68 accum_acc= 0.6536 t= 2.84300088882 sec\n",
      "(STEP 520) loss= 1.78028 acc= 0.68 accum_acc= 0.6602 t= 2.87959098816 sec\n",
      "(STEP 530) loss= 1.75128 acc= 0.72 accum_acc= 0.665 t= 2.9339568615 sec\n",
      "(STEP 540) loss= 1.65355 acc= 0.7 accum_acc= 0.6683 t= 2.96562695503 sec\n",
      "(STEP 550) loss= 1.67984 acc= 0.71 accum_acc= 0.6725 t= 2.99531078339 sec\n",
      "(STEP 560) loss= 1.5779 acc= 0.77 accum_acc= 0.6767 t= 3.0254240036 sec\n",
      "(STEP 570) loss= 1.6279 acc= 0.64 accum_acc= 0.68 t= 3.05968999863 sec\n",
      "(STEP 580) loss= 1.60472 acc= 0.7 accum_acc= 0.686 t= 3.09181690216 sec\n",
      "(STEP 590) loss= 1.64248 acc= 0.69 accum_acc= 0.6921 t= 3.14299082756 sec\n",
      "(STEP 599) loss= 1.53108 acc= 0.76 accum_acc= 0.6969 t= 3.20472693443 sec\n",
      "EPOCH: 2\n",
      "(STEP 600) loss= 1.54646 acc= 0.75 accum_acc= 0.6975 t= 3.96203684807 sec\n",
      "(STEP 610) loss= 1.52971 acc= 0.79 accum_acc= 0.703 t= 3.99132084846 sec\n",
      "(STEP 620) loss= 1.57822 acc= 0.69 accum_acc= 0.7066 t= 4.02727794647 sec\n",
      "(STEP 630) loss= 1.46932 acc= 0.78 accum_acc= 0.7124 t= 4.06044101715 sec\n",
      "(STEP 640) loss= 1.5171 acc= 0.71 accum_acc= 0.7153 t= 4.09037899971 sec\n",
      "(STEP 650) loss= 1.41823 acc= 0.75 accum_acc= 0.7193 t= 4.12024593353 sec\n",
      "(STEP 660) loss= 1.48275 acc= 0.71 accum_acc= 0.7231 t= 4.15052485466 sec\n",
      "(STEP 670) loss= 1.47181 acc= 0.72 accum_acc= 0.7242 t= 4.19558286667 sec\n",
      "(STEP 680) loss= 1.41799 acc= 0.78 accum_acc= 0.727 t= 4.24129486084 sec\n",
      "(STEP 690) loss= 1.25555 acc= 0.79 accum_acc= 0.7233 t= 4.27850198746 sec\n",
      "(STEP 700) loss= 1.39731 acc= 0.7 accum_acc= 0.7245 t= 4.3125038147 sec\n",
      "(STEP 710) loss= 1.275 acc= 0.8 accum_acc= 0.7275 t= 4.34151101112 sec\n",
      "(STEP 720) loss= 1.42459 acc= 0.73 accum_acc= 0.7312 t= 4.37608599663 sec\n",
      "(STEP 730) loss= 1.26115 acc= 0.78 accum_acc= 0.7353 t= 4.41628289223 sec\n",
      "(STEP 740) loss= 1.36789 acc= 0.66 accum_acc= 0.7341 t= 4.50382184982 sec\n",
      "(STEP 750) loss= 1.28404 acc= 0.75 accum_acc= 0.7336 t= 4.56489992142 sec\n",
      "(STEP 760) loss= 1.32036 acc= 0.7 accum_acc= 0.7364 t= 4.60314583778 sec\n",
      "(STEP 770) loss= 1.29922 acc= 0.73 accum_acc= 0.7384 t= 4.64297199249 sec\n",
      "(STEP 780) loss= 1.19569 acc= 0.77 accum_acc= 0.7405 t= 4.70599794388 sec\n",
      "(STEP 790) loss= 1.21116 acc= 0.72 accum_acc= 0.7462 t= 4.73686790466 sec\n",
      "(STEP 800) loss= 1.17741 acc= 0.74 accum_acc= 0.7499 t= 4.76906085014 sec\n",
      "(STEP 810) loss= 1.28226 acc= 0.71 accum_acc= 0.7494 t= 4.79909682274 sec\n",
      "(STEP 820) loss= 1.15375 acc= 0.77 accum_acc= 0.7493 t= 4.83348298073 sec\n",
      "(STEP 830) loss= 1.17548 acc= 0.75 accum_acc= 0.7504 t= 4.87460780144 sec\n",
      "(STEP 840) loss= 1.04963 acc= 0.84 accum_acc= 0.7579 t= 4.93444681168 sec\n",
      "(STEP 850) loss= 1.03844 acc= 0.78 accum_acc= 0.7637 t= 5.03087496758 sec\n",
      "(STEP 860) loss= 1.12186 acc= 0.8 accum_acc= 0.7657 t= 5.10682082176 sec\n",
      "(STEP 870) loss= 1.08725 acc= 0.8 accum_acc= 0.7688 t= 5.20197081566 sec\n",
      "(STEP 880) loss= 1.03947 acc= 0.77 accum_acc= 0.7726 t= 5.24545288086 sec\n",
      "(STEP 890) loss= 1.08154 acc= 0.77 accum_acc= 0.7754 t= 5.28203392029 sec\n",
      "(STEP 900) loss= 1.05609 acc= 0.75 accum_acc= 0.7773 t= 5.32827496529 sec\n",
      "(STEP 910) loss= 0.985351 acc= 0.82 accum_acc= 0.7798 t= 5.38158488274 sec\n",
      "(STEP 920) loss= 0.996529 acc= 0.83 accum_acc= 0.7822 t= 5.41746592522 sec\n",
      "(STEP 930) loss= 0.997836 acc= 0.79 accum_acc= 0.7854 t= 5.45399689674 sec\n",
      "(STEP 940) loss= 0.982069 acc= 0.8 accum_acc= 0.7845 t= 5.49237394333 sec\n",
      "(STEP 950) loss= 0.98658 acc= 0.8 accum_acc= 0.7864 t= 5.53008079529 sec\n",
      "(STEP 960) loss= 0.973957 acc= 0.81 accum_acc= 0.7883 t= 5.58089089394 sec\n",
      "(STEP 970) loss= 0.946224 acc= 0.78 accum_acc= 0.7892 t= 5.65007996559 sec\n",
      "(STEP 980) loss= 0.87968 acc= 0.83 accum_acc= 0.7921 t= 5.68922781944 sec\n",
      "(STEP 990) loss= 0.895852 acc= 0.86 accum_acc= 0.797 t= 5.71921896935 sec\n",
      "(STEP 1000) loss= 0.957365 acc= 0.76 accum_acc= 0.7986 t= 5.75562000275 sec\n",
      "(STEP 1010) loss= 0.9127 acc= 0.81 accum_acc= 0.8002 t= 5.78952789307 sec\n",
      "(STEP 1020) loss= 0.924417 acc= 0.81 accum_acc= 0.804 t= 5.83625078201 sec\n",
      "(STEP 1030) loss= 0.862844 acc= 0.81 accum_acc= 0.8061 t= 5.86865091324 sec\n",
      "(STEP 1040) loss= 0.870609 acc= 0.82 accum_acc= 0.8085 t= 5.89872384071 sec\n",
      "(STEP 1050) loss= 0.870027 acc= 0.82 accum_acc= 0.8095 t= 5.92857599258 sec\n",
      "(STEP 1060) loss= 0.868798 acc= 0.76 accum_acc= 0.8098 t= 5.95786786079 sec\n",
      "(STEP 1070) loss= 0.743234 acc= 0.82 accum_acc= 0.8107 t= 5.99705886841 sec\n",
      "(STEP 1080) loss= 0.823592 acc= 0.83 accum_acc= 0.8142 t= 6.02719497681 sec\n",
      "(STEP 1090) loss= 0.786671 acc= 0.83 accum_acc= 0.8147 t= 6.05653786659 sec\n",
      "(STEP 1100) loss= 0.849513 acc= 0.78 accum_acc= 0.8164 t= 6.09293794632 sec\n",
      "(STEP 1110) loss= 0.766647 acc= 0.84 accum_acc= 0.8188 t= 6.12621283531 sec\n",
      "(STEP 1120) loss= 0.770972 acc= 0.86 accum_acc= 0.8202 t= 6.16089296341 sec\n",
      "(STEP 1130) loss= 0.693468 acc= 0.83 accum_acc= 0.821 t= 6.19602894783 sec\n",
      "(STEP 1140) loss= 0.783262 acc= 0.8 accum_acc= 0.823 t= 6.23382496834 sec\n",
      "(STEP 1150) loss= 0.785682 acc= 0.8 accum_acc= 0.8234 t= 6.2685790062 sec\n",
      "(STEP 1160) loss= 0.845284 acc= 0.82 accum_acc= 0.827 t= 6.3032989502 sec\n",
      "(STEP 1170) loss= 0.700674 acc= 0.88 accum_acc= 0.8318 t= 6.34978890419 sec\n",
      "(STEP 1180) loss= 0.777638 acc= 0.8 accum_acc= 0.8275 t= 6.38691878319 sec\n",
      "(STEP 1190) loss= 0.937799 acc= 0.75 accum_acc= 0.8271 t= 6.580701828 sec\n",
      "(STEP 1199) loss= 0.853951 acc= 0.81 accum_acc= 0.8273 t= 6.63864994049 sec\n",
      "EPOCH: 3\n",
      "(STEP 1200) loss= 0.757161 acc= 0.83 accum_acc= 0.8278 t= 7.09699988365 sec\n",
      "(STEP 1210) loss= 0.75164 acc= 0.83 accum_acc= 0.8285 t= 7.12621498108 sec\n",
      "(STEP 1220) loss= 0.69928 acc= 0.85 accum_acc= 0.8302 t= 7.1617898941 sec\n",
      "(STEP 1230) loss= 0.73982 acc= 0.82 accum_acc= 0.8331 t= 7.19536495209 sec\n",
      "(STEP 1240) loss= 0.719607 acc= 0.81 accum_acc= 0.8335 t= 7.22872281075 sec\n",
      "(STEP 1250) loss= 0.77265 acc= 0.81 accum_acc= 0.8354 t= 7.26572585106 sec\n",
      "(STEP 1260) loss= 0.640924 acc= 0.86 accum_acc= 0.8372 t= 7.31227493286 sec\n",
      "(STEP 1270) loss= 0.705259 acc= 0.85 accum_acc= 0.8363 t= 7.36453485489 sec\n",
      "(STEP 1280) loss= 0.796616 acc= 0.72 accum_acc= 0.8376 t= 7.39897489548 sec\n",
      "(STEP 1290) loss= 0.718293 acc= 0.84 accum_acc= 0.8377 t= 7.42938995361 sec\n",
      "(STEP 1300) loss= 0.613633 acc= 0.85 accum_acc= 0.8392 t= 7.46012401581 sec\n",
      "(STEP 1310) loss= 0.774538 acc= 0.8 accum_acc= 0.8394 t= 7.49131393433 sec\n",
      "(STEP 1320) loss= 0.654829 acc= 0.87 accum_acc= 0.8377 t= 7.55364394188 sec\n",
      "(STEP 1330) loss= 0.787522 acc= 0.83 accum_acc= 0.8364 t= 7.65641999245 sec\n",
      "(STEP 1340) loss= 0.589428 acc= 0.88 accum_acc= 0.8375 t= 7.73140692711 sec\n",
      "(STEP 1350) loss= 0.639467 acc= 0.87 accum_acc= 0.8375 t= 7.76963996887 sec\n",
      "(STEP 1360) loss= 0.58887 acc= 0.9 accum_acc= 0.8373 t= 7.81092596054 sec\n",
      "(STEP 1370) loss= 0.660569 acc= 0.85 accum_acc= 0.8396 t= 7.86335897446 sec\n",
      "(STEP 1380) loss= 0.76234 acc= 0.85 accum_acc= 0.8438 t= 7.90510392189 sec\n",
      "(STEP 1390) loss= 0.686442 acc= 0.83 accum_acc= 0.8453 t= 7.94717788696 sec\n",
      "(STEP 1400) loss= 0.584209 acc= 0.87 accum_acc= 0.8473 t= 7.97976899147 sec\n",
      "(STEP 1410) loss= 0.686711 acc= 0.81 accum_acc= 0.8472 t= 8.01880383492 sec\n",
      "(STEP 1420) loss= 0.599633 acc= 0.88 accum_acc= 0.8503 t= 8.07535481453 sec\n",
      "(STEP 1430) loss= 0.593893 acc= 0.9 accum_acc= 0.852 t= 8.1566388607 sec\n",
      "(STEP 1440) loss= 0.751325 acc= 0.81 accum_acc= 0.8525 t= 8.21935200691 sec\n",
      "(STEP 1450) loss= 0.666933 acc= 0.8 accum_acc= 0.8516 t= 8.27352881432 sec\n",
      "(STEP 1460) loss= 0.598828 acc= 0.88 accum_acc= 0.8518 t= 8.30406498909 sec\n",
      "(STEP 1470) loss= 0.612831 acc= 0.85 accum_acc= 0.8513 t= 8.33767580986 sec\n",
      "(STEP 1480) loss= 0.531904 acc= 0.88 accum_acc= 0.8511 t= 8.36768889427 sec\n",
      "(STEP 1490) loss= 0.573346 acc= 0.88 accum_acc= 0.8529 t= 8.3979268074 sec\n",
      "(STEP 1500) loss= 0.708846 acc= 0.79 accum_acc= 0.8529 t= 8.42901086807 sec\n",
      "(STEP 1510) loss= 0.462456 acc= 0.92 accum_acc= 0.857 t= 8.46746301651 sec\n",
      "(STEP 1520) loss= 0.540889 acc= 0.86 accum_acc= 0.8555 t= 8.49799394608 sec\n",
      "(STEP 1530) loss= 0.520801 acc= 0.88 accum_acc= 0.8536 t= 8.52750301361 sec\n",
      "(STEP 1540) loss= 0.57968 acc= 0.88 accum_acc= 0.8545 t= 8.55750393867 sec\n",
      "(STEP 1550) loss= 0.546626 acc= 0.88 accum_acc= 0.8584 t= 8.59194397926 sec\n",
      "(STEP 1560) loss= 0.644891 acc= 0.84 accum_acc= 0.8593 t= 8.62268900871 sec\n",
      "(STEP 1570) loss= 0.65564 acc= 0.87 accum_acc= 0.861 t= 8.66253495216 sec\n",
      "(STEP 1580) loss= 0.680483 acc= 0.83 accum_acc= 0.8606 t= 8.69584298134 sec\n",
      "(STEP 1590) loss= 0.522745 acc= 0.87 accum_acc= 0.8597 t= 8.73084783554 sec\n",
      "(STEP 1600) loss= 0.663494 acc= 0.79 accum_acc= 0.8577 t= 8.79148983955 sec\n",
      "(STEP 1610) loss= 0.536827 acc= 0.85 accum_acc= 0.8568 t= 8.89535784721 sec\n",
      "(STEP 1620) loss= 0.431453 acc= 0.87 accum_acc= 0.8585 t= 8.97398400307 sec\n",
      "(STEP 1630) loss= 0.586914 acc= 0.86 accum_acc= 0.8594 t= 9.00514984131 sec\n",
      "(STEP 1640) loss= 0.569216 acc= 0.83 accum_acc= 0.8593 t= 9.03478693962 sec\n",
      "(STEP 1650) loss= 0.519374 acc= 0.86 accum_acc= 0.8572 t= 9.07997894287 sec\n",
      "(STEP 1660) loss= 0.448533 acc= 0.91 accum_acc= 0.8577 t= 9.11315083504 sec\n",
      "(STEP 1670) loss= 0.46297 acc= 0.94 accum_acc= 0.8568 t= 9.15560078621 sec\n",
      "(STEP 1680) loss= 0.524274 acc= 0.86 accum_acc= 0.8565 t= 9.1901409626 sec\n",
      "(STEP 1690) loss= 0.523127 acc= 0.87 accum_acc= 0.8591 t= 9.21952700615 sec\n",
      "(STEP 1700) loss= 0.585585 acc= 0.86 accum_acc= 0.8598 t= 9.24909901619 sec\n",
      "(STEP 1710) loss= 0.440483 acc= 0.88 accum_acc= 0.859 t= 9.27890396118 sec\n",
      "(STEP 1720) loss= 0.521795 acc= 0.86 accum_acc= 0.8577 t= 9.30918192863 sec\n",
      "(STEP 1730) loss= 0.561096 acc= 0.85 accum_acc= 0.8596 t= 9.35459184647 sec\n",
      "(STEP 1740) loss= 0.396364 acc= 0.92 accum_acc= 0.8615 t= 9.40425801277 sec\n",
      "(STEP 1750) loss= 0.572486 acc= 0.85 accum_acc= 0.8623 t= 9.47196578979 sec\n",
      "(STEP 1760) loss= 0.496925 acc= 0.93 accum_acc= 0.8615 t= 9.52727389336 sec\n",
      "(STEP 1770) loss= 0.495734 acc= 0.9 accum_acc= 0.8627 t= 9.5930287838 sec\n",
      "(STEP 1780) loss= 0.548998 acc= 0.84 accum_acc= 0.865 t= 9.63068890572 sec\n",
      "(STEP 1790) loss= 0.457002 acc= 0.87 accum_acc= 0.8628 t= 9.66094994545 sec\n",
      "(STEP 1799) loss= 0.457855 acc= 0.87 accum_acc= 0.8626 t= 9.68776679039 sec\n",
      "EPOCH: 4\n",
      "(STEP 1800) loss= 0.588638 acc= 0.85 accum_acc= 0.8625 t= 10.1072149277 sec\n",
      "(STEP 1810) loss= 0.552445 acc= 0.86 accum_acc= 0.8613 t= 10.1886048317 sec\n",
      "(STEP 1820) loss= 0.43828 acc= 0.89 accum_acc= 0.8621 t= 10.2440779209 sec\n",
      "(STEP 1830) loss= 0.535608 acc= 0.88 accum_acc= 0.8631 t= 10.2741119862 sec\n",
      "(STEP 1840) loss= 0.439682 acc= 0.88 accum_acc= 0.8623 t= 10.3033249378 sec\n",
      "(STEP 1850) loss= 0.417595 acc= 0.91 accum_acc= 0.863 t= 10.3482348919 sec\n",
      "(STEP 1860) loss= 0.534996 acc= 0.85 accum_acc= 0.8648 t= 10.378210783 sec\n",
      "(STEP 1870) loss= 0.416575 acc= 0.88 accum_acc= 0.8635 t= 10.4081728458 sec\n",
      "(STEP 1880) loss= 0.655262 acc= 0.87 accum_acc= 0.862 t= 10.4375460148 sec\n",
      "(STEP 1890) loss= 0.376896 acc= 0.91 accum_acc= 0.8646 t= 10.4673578739 sec\n",
      "(STEP 1900) loss= 0.467144 acc= 0.91 accum_acc= 0.8673 t= 10.4967579842 sec\n",
      "(STEP 1910) loss= 0.514548 acc= 0.9 accum_acc= 0.8675 t= 10.5344228745 sec\n",
      "(STEP 1920) loss= 0.424229 acc= 0.89 accum_acc= 0.8674 t= 10.6127138138 sec\n",
      "(STEP 1930) loss= 0.504011 acc= 0.89 accum_acc= 0.8687 t= 10.7056548595 sec\n",
      "(STEP 1940) loss= 0.58629 acc= 0.82 accum_acc= 0.8691 t= 10.7738509178 sec\n",
      "(STEP 1950) loss= 0.464543 acc= 0.86 accum_acc= 0.87 t= 10.8124198914 sec\n",
      "(STEP 1960) loss= 0.538693 acc= 0.9 accum_acc= 0.8714 t= 10.8611359596 sec\n",
      "(STEP 1970) loss= 0.458649 acc= 0.9 accum_acc= 0.8747 t= 10.8934588432 sec\n",
      "(STEP 1980) loss= 0.410182 acc= 0.91 accum_acc= 0.8771 t= 10.9229009151 sec\n",
      "(STEP 1990) loss= 0.454232 acc= 0.92 accum_acc= 0.8765 t= 10.968225956 sec\n",
      "(STEP 2000) loss= 0.576987 acc= 0.85 accum_acc= 0.8758 t= 11.0438067913 sec\n",
      "(STEP 2010) loss= 0.514006 acc= 0.86 accum_acc= 0.8796 t= 11.1274077892 sec\n",
      "(STEP 2020) loss= 0.52905 acc= 0.83 accum_acc= 0.8803 t= 11.1825449467 sec\n",
      "(STEP 2030) loss= 0.445819 acc= 0.88 accum_acc= 0.8765 t= 11.2133729458 sec\n",
      "(STEP 2040) loss= 0.514967 acc= 0.88 accum_acc= 0.8769 t= 11.2432949543 sec\n",
      "(STEP 2050) loss= 0.443792 acc= 0.87 accum_acc= 0.8767 t= 11.2727220058 sec\n",
      "(STEP 2060) loss= 0.423427 acc= 0.92 accum_acc= 0.8767 t= 11.3017799854 sec\n",
      "(STEP 2070) loss= 0.452837 acc= 0.9 accum_acc= 0.8748 t= 11.3355679512 sec\n",
      "(STEP 2080) loss= 0.47804 acc= 0.85 accum_acc= 0.8735 t= 11.3731060028 sec\n",
      "(STEP 2090) loss= 0.393136 acc= 0.95 accum_acc= 0.8752 t= 11.407864809 sec\n",
      "(STEP 2100) loss= 0.595705 acc= 0.78 accum_acc= 0.8731 t= 11.4825007915 sec\n",
      "(STEP 2110) loss= 0.424509 acc= 0.91 accum_acc= 0.8707 t= 11.5504620075 sec\n",
      "(STEP 2120) loss= 0.416495 acc= 0.89 accum_acc= 0.87 t= 11.6246190071 sec\n",
      "(STEP 2130) loss= 0.408261 acc= 0.87 accum_acc= 0.871 t= 11.6614058018 sec\n",
      "(STEP 2140) loss= 0.45768 acc= 0.86 accum_acc= 0.8717 t= 11.6906118393 sec\n",
      "(STEP 2150) loss= 0.581371 acc= 0.87 accum_acc= 0.8736 t= 11.7194809914 sec\n",
      "(STEP 2160) loss= 0.491712 acc= 0.89 accum_acc= 0.8704 t= 11.74898386 sec\n",
      "(STEP 2170) loss= 0.466593 acc= 0.88 accum_acc= 0.8715 t= 11.7917149067 sec\n",
      "(STEP 2180) loss= 0.687732 acc= 0.82 accum_acc= 0.872 t= 11.907460928 sec\n",
      "(STEP 2190) loss= 0.347209 acc= 0.91 accum_acc= 0.8703 t= 11.9917287827 sec\n",
      "(STEP 2200) loss= 0.552518 acc= 0.86 accum_acc= 0.8719 t= 12.0572938919 sec\n",
      "(STEP 2210) loss= 0.481316 acc= 0.83 accum_acc= 0.875 t= 12.0956299305 sec\n",
      "(STEP 2220) loss= 0.506377 acc= 0.88 accum_acc= 0.8781 t= 12.1279828548 sec\n",
      "(STEP 2230) loss= 0.310684 acc= 0.92 accum_acc= 0.8817 t= 12.2160038948 sec\n",
      "(STEP 2240) loss= 0.546293 acc= 0.84 accum_acc= 0.8804 t= 12.2834939957 sec\n",
      "(STEP 2250) loss= 0.523429 acc= 0.89 accum_acc= 0.8799 t= 12.3465528488 sec\n",
      "(STEP 2260) loss= 0.486888 acc= 0.88 accum_acc= 0.8813 t= 12.4195837975 sec\n",
      "(STEP 2270) loss= 0.387544 acc= 0.93 accum_acc= 0.8814 t= 12.4571259022 sec\n",
      "(STEP 2280) loss= 0.586825 acc= 0.82 accum_acc= 0.8812 t= 12.4873118401 sec\n",
      "(STEP 2290) loss= 0.447053 acc= 0.88 accum_acc= 0.883 t= 12.5265870094 sec\n",
      "(STEP 2300) loss= 0.300695 acc= 0.97 accum_acc= 0.8851 t= 12.6104078293 sec\n",
      "(STEP 2310) loss= 0.501911 acc= 0.89 accum_acc= 0.8851 t= 12.6954469681 sec\n",
      "(STEP 2320) loss= 0.334131 acc= 0.93 accum_acc= 0.8844 t= 12.7614297867 sec\n",
      "(STEP 2330) loss= 0.379967 acc= 0.92 accum_acc= 0.8831 t= 12.8108408451 sec\n",
      "(STEP 2340) loss= 0.566419 acc= 0.87 accum_acc= 0.8837 t= 12.8560907841 sec\n",
      "(STEP 2350) loss= 0.388318 acc= 0.89 accum_acc= 0.8842 t= 12.8871309757 sec\n",
      "(STEP 2360) loss= 0.445458 acc= 0.88 accum_acc= 0.8846 t= 12.9666450024 sec\n",
      "(STEP 2370) loss= 0.391449 acc= 0.89 accum_acc= 0.8836 t= 13.0446488857 sec\n",
      "(STEP 2380) loss= 0.423061 acc= 0.89 accum_acc= 0.8855 t= 13.1182909012 sec\n",
      "(STEP 2390) loss= 0.48108 acc= 0.88 accum_acc= 0.8848 t= 13.1513040066 sec\n",
      "(STEP 2399) loss= 0.444988 acc= 0.89 accum_acc= 0.8838 t= 13.1819169521 sec\n",
      "EPOCH: 5\n",
      "(STEP 2400) loss= 0.407723 acc= 0.89 accum_acc= 0.883 t= 13.5773768425 sec\n",
      "(STEP 2410) loss= 0.504844 acc= 0.83 accum_acc= 0.8808 t= 13.6128509045 sec\n",
      "(STEP 2420) loss= 0.441739 acc= 0.86 accum_acc= 0.8794 t= 13.6446208954 sec\n",
      "(STEP 2430) loss= 0.407474 acc= 0.88 accum_acc= 0.8792 t= 13.7074170113 sec\n",
      "(STEP 2440) loss= 0.290608 acc= 0.95 accum_acc= 0.8811 t= 13.7843399048 sec\n",
      "(STEP 2450) loss= 0.457866 acc= 0.87 accum_acc= 0.8805 t= 13.8564260006 sec\n",
      "(STEP 2460) loss= 0.407861 acc= 0.87 accum_acc= 0.8829 t= 13.9148368835 sec\n",
      "(STEP 2470) loss= 0.496665 acc= 0.86 accum_acc= 0.8831 t= 13.9552268982 sec\n",
      "(STEP 2480) loss= 0.47909 acc= 0.87 accum_acc= 0.8817 t= 14.0136659145 sec\n",
      "(STEP 2490) loss= 0.432019 acc= 0.88 accum_acc= 0.8822 t= 14.0669329166 sec\n",
      "(STEP 2500) loss= 0.498676 acc= 0.89 accum_acc= 0.8851 t= 14.1221117973 sec\n",
      "(STEP 2510) loss= 0.440527 acc= 0.85 accum_acc= 0.888 t= 14.1640210152 sec\n",
      "(STEP 2520) loss= 0.467495 acc= 0.89 accum_acc= 0.8895 t= 14.2050759792 sec\n",
      "(STEP 2530) loss= 0.377921 acc= 0.91 accum_acc= 0.8886 t= 14.2452278137 sec\n",
      "(STEP 2540) loss= 0.359088 acc= 0.88 accum_acc= 0.8892 t= 14.2793037891 sec\n",
      "(STEP 2550) loss= 0.39218 acc= 0.9 accum_acc= 0.889 t= 14.3091628551 sec\n",
      "(STEP 2560) loss= 0.577928 acc= 0.82 accum_acc= 0.8871 t= 14.3454809189 sec\n",
      "(STEP 2570) loss= 0.315419 acc= 0.89 accum_acc= 0.8879 t= 14.377560854 sec\n",
      "(STEP 2580) loss= 0.514269 acc= 0.87 accum_acc= 0.8893 t= 14.4147818089 sec\n",
      "(STEP 2590) loss= 0.365902 acc= 0.91 accum_acc= 0.8899 t= 14.4500308037 sec\n",
      "(STEP 2600) loss= 0.482434 acc= 0.89 accum_acc= 0.8882 t= 14.4896149635 sec\n",
      "(STEP 2610) loss= 0.442125 acc= 0.86 accum_acc= 0.8858 t= 14.5374689102 sec\n",
      "(STEP 2620) loss= 0.303924 acc= 0.94 accum_acc= 0.8854 t= 14.571792841 sec\n",
      "(STEP 2630) loss= 0.413895 acc= 0.9 accum_acc= 0.8862 t= 14.6133439541 sec\n",
      "(STEP 2640) loss= 0.448297 acc= 0.87 accum_acc= 0.8843 t= 14.6606059074 sec\n",
      "(STEP 2650) loss= 0.449876 acc= 0.89 accum_acc= 0.8843 t= 14.7411179543 sec\n",
      "(STEP 2660) loss= 0.479382 acc= 0.87 accum_acc= 0.8845 t= 14.8596367836 sec\n",
      "(STEP 2670) loss= 0.453795 acc= 0.86 accum_acc= 0.885 t= 14.9083099365 sec\n",
      "(STEP 2680) loss= 0.437306 acc= 0.84 accum_acc= 0.8851 t= 14.9439678192 sec\n",
      "(STEP 2690) loss= 0.399621 acc= 0.88 accum_acc= 0.8835 t= 14.9733419418 sec\n",
      "(STEP 2700) loss= 0.484875 acc= 0.86 accum_acc= 0.8835 t= 15.0334279537 sec\n",
      "(STEP 2710) loss= 0.549644 acc= 0.87 accum_acc= 0.8851 t= 15.1439788342 sec\n",
      "(STEP 2720) loss= 0.59021 acc= 0.84 accum_acc= 0.8858 t= 15.2158458233 sec\n",
      "(STEP 2730) loss= 0.285231 acc= 0.91 accum_acc= 0.8878 t= 15.2534248829 sec\n",
      "(STEP 2740) loss= 0.376628 acc= 0.88 accum_acc= 0.8896 t= 15.2839357853 sec\n",
      "(STEP 2750) loss= 0.425603 acc= 0.88 accum_acc= 0.8891 t= 15.313710928 sec\n",
      "(STEP 2760) loss= 0.527051 acc= 0.83 accum_acc= 0.889 t= 15.3498039246 sec\n",
      "(STEP 2770) loss= 0.503012 acc= 0.84 accum_acc= 0.8895 t= 15.388422966 sec\n",
      "(STEP 2780) loss= 0.344723 acc= 0.9 accum_acc= 0.8899 t= 15.4233357906 sec\n",
      "(STEP 2790) loss= 0.353206 acc= 0.9 accum_acc= 0.89 t= 15.4777448177 sec\n",
      "(STEP 2800) loss= 0.406445 acc= 0.88 accum_acc= 0.8909 t= 15.5650508404 sec\n",
      "(STEP 2810) loss= 0.33422 acc= 0.9 accum_acc= 0.891 t= 15.6263887882 sec\n",
      "(STEP 2820) loss= 0.389343 acc= 0.85 accum_acc= 0.8919 t= 15.6888899803 sec\n",
      "(STEP 2830) loss= 0.51537 acc= 0.88 accum_acc= 0.8889 t= 15.7194268703 sec\n",
      "(STEP 2840) loss= 0.389559 acc= 0.89 accum_acc= 0.8876 t= 15.7494208813 sec\n",
      "(STEP 2850) loss= 0.438948 acc= 0.88 accum_acc= 0.8887 t= 15.7817699909 sec\n",
      "(STEP 2860) loss= 0.415227 acc= 0.86 accum_acc= 0.8898 t= 15.9050848484 sec\n",
      "(STEP 2870) loss= 0.426282 acc= 0.89 accum_acc= 0.8903 t= 15.9904358387 sec\n",
      "(STEP 2880) loss= 0.370218 acc= 0.95 accum_acc= 0.89 t= 16.0386149883 sec\n",
      "(STEP 2890) loss= 0.317032 acc= 0.91 accum_acc= 0.8917 t= 16.07584095 sec\n",
      "(STEP 2900) loss= 0.494834 acc= 0.88 accum_acc= 0.8921 t= 16.1171629429 sec\n",
      "(STEP 2910) loss= 0.538619 acc= 0.88 accum_acc= 0.8916 t= 16.2071089745 sec\n",
      "(STEP 2920) loss= 0.486409 acc= 0.88 accum_acc= 0.8902 t= 16.269742012 sec\n",
      "(STEP 2930) loss= 0.612182 acc= 0.84 accum_acc= 0.8889 t= 16.3415038586 sec\n",
      "(STEP 2940) loss= 0.395838 acc= 0.92 accum_acc= 0.8888 t= 16.3902537823 sec\n",
      "(STEP 2950) loss= 0.351784 acc= 0.91 accum_acc= 0.8884 t= 16.4226248264 sec\n",
      "(STEP 2960) loss= 0.326914 acc= 0.92 accum_acc= 0.888 t= 16.4620850086 sec\n",
      "(STEP 2970) loss= 0.315854 acc= 0.91 accum_acc= 0.8878 t= 16.4939608574 sec\n",
      "(STEP 2980) loss= 0.422333 acc= 0.88 accum_acc= 0.8877 t= 16.5233459473 sec\n",
      "(STEP 2990) loss= 0.509802 acc= 0.88 accum_acc= 0.8872 t= 16.5536019802 sec\n",
      "(STEP 2999) loss= 0.322928 acc= 0.91 accum_acc= 0.8868 t= 16.5923259258 sec\n",
      "EPOCH: 6\n",
      "(STEP 3000) loss= 0.487358 acc= 0.87 accum_acc= 0.8867 t= 16.9976580143 sec\n",
      "(STEP 3010) loss= 0.462712 acc= 0.87 accum_acc= 0.8855 t= 17.0277688503 sec\n",
      "(STEP 3020) loss= 0.433195 acc= 0.91 accum_acc= 0.887 t= 17.057489872 sec\n",
      "(STEP 3030) loss= 0.314328 acc= 0.9 accum_acc= 0.8896 t= 17.0882158279 sec\n",
      "(STEP 3040) loss= 0.345492 acc= 0.92 accum_acc= 0.8905 t= 17.2103898525 sec\n",
      "(STEP 3050) loss= 0.512968 acc= 0.89 accum_acc= 0.8917 t= 17.2847728729 sec\n",
      "(STEP 3060) loss= 0.327494 acc= 0.93 accum_acc= 0.891 t= 17.3206319809 sec\n",
      "(STEP 3070) loss= 0.560744 acc= 0.89 accum_acc= 0.892 t= 17.3553738594 sec\n",
      "(STEP 3080) loss= 0.265139 acc= 0.96 accum_acc= 0.8928 t= 17.3851230145 sec\n",
      "(STEP 3090) loss= 0.659092 acc= 0.85 accum_acc= 0.8918 t= 17.4168429375 sec\n",
      "(STEP 3100) loss= 0.374961 acc= 0.88 accum_acc= 0.8901 t= 17.4549899101 sec\n",
      "(STEP 3110) loss= 0.370811 acc= 0.92 accum_acc= 0.892 t= 17.488214016 sec\n",
      "(STEP 3120) loss= 0.320119 acc= 0.91 accum_acc= 0.8927 t= 17.5174298286 sec\n",
      "(STEP 3130) loss= 0.373739 acc= 0.89 accum_acc= 0.8946 t= 17.5583570004 sec\n",
      "(STEP 3140) loss= 0.435409 acc= 0.84 accum_acc= 0.8947 t= 17.5891358852 sec\n",
      "(STEP 3150) loss= 0.426122 acc= 0.85 accum_acc= 0.8942 t= 17.6303069592 sec\n",
      "(STEP 3160) loss= 0.340421 acc= 0.92 accum_acc= 0.8951 t= 17.6909058094 sec\n",
      "(STEP 3170) loss= 0.319028 acc= 0.93 accum_acc= 0.8937 t= 17.7772209644 sec\n",
      "(STEP 3180) loss= 0.455521 acc= 0.84 accum_acc= 0.8923 t= 17.8430728912 sec\n",
      "(STEP 3190) loss= 0.539368 acc= 0.86 accum_acc= 0.8928 t= 17.8926758766 sec\n",
      "(STEP 3200) loss= 0.456543 acc= 0.89 accum_acc= 0.8954 t= 17.9235448837 sec\n",
      "(STEP 3210) loss= 0.356154 acc= 0.88 accum_acc= 0.8948 t= 17.9532268047 sec\n",
      "(STEP 3220) loss= 0.272336 acc= 0.92 accum_acc= 0.8934 t= 17.9826858044 sec\n",
      "(STEP 3230) loss= 0.391926 acc= 0.9 accum_acc= 0.8924 t= 18.0354728699 sec\n",
      "(STEP 3240) loss= 0.372194 acc= 0.93 accum_acc= 0.8922 t= 18.1176998615 sec\n",
      "(STEP 3250) loss= 0.316362 acc= 0.93 accum_acc= 0.8933 t= 18.2099399567 sec\n",
      "(STEP 3260) loss= 0.373399 acc= 0.88 accum_acc= 0.8932 t= 18.2799668312 sec\n",
      "(STEP 3270) loss= 0.359072 acc= 0.93 accum_acc= 0.8928 t= 18.3126490116 sec\n",
      "(STEP 3280) loss= 0.439599 acc= 0.89 accum_acc= 0.8941 t= 18.3649058342 sec\n",
      "(STEP 3290) loss= 0.363379 acc= 0.9 accum_acc= 0.8931 t= 18.4647908211 sec\n",
      "(STEP 3300) loss= 0.394877 acc= 0.89 accum_acc= 0.8905 t= 18.5358808041 sec\n",
      "(STEP 3310) loss= 0.492982 acc= 0.88 accum_acc= 0.8913 t= 18.5935130119 sec\n",
      "(STEP 3320) loss= 0.296549 acc= 0.93 accum_acc= 0.8915 t= 18.6385629177 sec\n",
      "(STEP 3330) loss= 0.296544 acc= 0.91 accum_acc= 0.8912 t= 18.6684949398 sec\n",
      "(STEP 3340) loss= 0.360196 acc= 0.93 accum_acc= 0.8922 t= 18.6982200146 sec\n",
      "(STEP 3350) loss= 0.29966 acc= 0.92 accum_acc= 0.891 t= 18.728058815 sec\n",
      "(STEP 3360) loss= 0.348088 acc= 0.91 accum_acc= 0.8907 t= 18.7602818012 sec\n",
      "(STEP 3370) loss= 0.426365 acc= 0.91 accum_acc= 0.8926 t= 18.7900869846 sec\n",
      "(STEP 3380) loss= 0.354125 acc= 0.88 accum_acc= 0.8919 t= 18.8249659538 sec\n",
      "(STEP 3390) loss= 0.610223 acc= 0.83 accum_acc= 0.893 t= 18.8713848591 sec\n",
      "(STEP 3400) loss= 0.359595 acc= 0.87 accum_acc= 0.8943 t= 18.9009239674 sec\n",
      "(STEP 3410) loss= 0.301517 acc= 0.91 accum_acc= 0.8936 t= 18.9365079403 sec\n",
      "(STEP 3420) loss= 0.340888 acc= 0.93 accum_acc= 0.8934 t= 18.9769020081 sec\n",
      "(STEP 3430) loss= 0.318774 acc= 0.94 accum_acc= 0.8937 t= 19.0235629082 sec\n",
      "(STEP 3440) loss= 0.407353 acc= 0.89 accum_acc= 0.8917 t= 19.0945358276 sec\n",
      "(STEP 3450) loss= 0.275465 acc= 0.95 accum_acc= 0.8935 t= 19.1477119923 sec\n",
      "(STEP 3460) loss= 0.459549 acc= 0.9 accum_acc= 0.8958 t= 19.2010838985 sec\n",
      "(STEP 3470) loss= 0.432161 acc= 0.87 accum_acc= 0.8939 t= 19.2468187809 sec\n",
      "(STEP 3480) loss= 0.370187 acc= 0.87 accum_acc= 0.8948 t= 19.303278923 sec\n",
      "(STEP 3490) loss= 0.385098 acc= 0.87 accum_acc= 0.8949 t= 19.3753159046 sec\n",
      "(STEP 3500) loss= 0.456121 acc= 0.86 accum_acc= 0.8946 t= 19.4268088341 sec\n",
      "(STEP 3510) loss= 0.259075 acc= 0.94 accum_acc= 0.8952 t= 19.4691879749 sec\n",
      "(STEP 3520) loss= 0.2392 acc= 0.91 accum_acc= 0.8954 t= 19.5026628971 sec\n",
      "(STEP 3530) loss= 0.418266 acc= 0.89 accum_acc= 0.8956 t= 19.54398489 sec\n",
      "(STEP 3540) loss= 0.44117 acc= 0.86 accum_acc= 0.8973 t= 19.652725935 sec\n",
      "(STEP 3550) loss= 0.314698 acc= 0.92 accum_acc= 0.8979 t= 19.7268979549 sec\n",
      "(STEP 3560) loss= 0.44548 acc= 0.89 accum_acc= 0.8955 t= 19.7655580044 sec\n",
      "(STEP 3570) loss= 0.25995 acc= 0.93 accum_acc= 0.8968 t= 19.8043158054 sec\n",
      "(STEP 3580) loss= 0.37786 acc= 0.87 accum_acc= 0.8955 t= 19.8346409798 sec\n",
      "(STEP 3590) loss= 0.346435 acc= 0.9 accum_acc= 0.8971 t= 19.8775479794 sec\n",
      "(STEP 3599) loss= 0.247988 acc= 0.93 accum_acc= 0.8987 t= 19.9045209885 sec\n",
      "EPOCH: 7\n",
      "(STEP 3600) loss= 0.358811 acc= 0.9 accum_acc= 0.8991 t= 20.3905308247 sec\n",
      "(STEP 3610) loss= 0.342168 acc= 0.92 accum_acc= 0.9 t= 20.4226529598 sec\n",
      "(STEP 3620) loss= 0.301685 acc= 0.94 accum_acc= 0.8999 t= 20.4526538849 sec\n",
      "(STEP 3630) loss= 0.276693 acc= 0.94 accum_acc= 0.9006 t= 20.4820489883 sec\n",
      "(STEP 3640) loss= 0.412638 acc= 0.84 accum_acc= 0.8992 t= 20.5126068592 sec\n",
      "(STEP 3650) loss= 0.549245 acc= 0.83 accum_acc= 0.8958 t= 20.5451359749 sec\n",
      "(STEP 3660) loss= 0.346167 acc= 0.9 accum_acc= 0.8976 t= 20.6423249245 sec\n",
      "(STEP 3670) loss= 0.364852 acc= 0.88 accum_acc= 0.8972 t= 20.6954298019 sec\n",
      "(STEP 3680) loss= 0.368334 acc= 0.9 accum_acc= 0.8978 t= 20.7890539169 sec\n",
      "(STEP 3690) loss= 0.491945 acc= 0.86 accum_acc= 0.897 t= 20.819216013 sec\n",
      "(STEP 3700) loss= 0.303663 acc= 0.93 accum_acc= 0.8971 t= 20.8563079834 sec\n",
      "(STEP 3710) loss= 0.423668 acc= 0.88 accum_acc= 0.8961 t= 20.9028759003 sec\n",
      "(STEP 3720) loss= 0.30838 acc= 0.9 accum_acc= 0.8965 t= 20.9634208679 sec\n",
      "(STEP 3730) loss= 0.293374 acc= 0.92 accum_acc= 0.8953 t= 21.0361769199 sec\n",
      "(STEP 3740) loss= 0.408158 acc= 0.86 accum_acc= 0.8965 t= 21.0899338722 sec\n",
      "(STEP 3750) loss= 0.387517 acc= 0.83 accum_acc= 0.8986 t= 21.1509609222 sec\n",
      "(STEP 3760) loss= 0.281859 acc= 0.94 accum_acc= 0.8983 t= 21.2003648281 sec\n",
      "(STEP 3770) loss= 0.338368 acc= 0.92 accum_acc= 0.8992 t= 21.2306787968 sec\n",
      "(STEP 3780) loss= 0.438528 acc= 0.87 accum_acc= 0.8983 t= 21.2607178688 sec\n",
      "(STEP 3790) loss= 0.510801 acc= 0.87 accum_acc= 0.8991 t= 21.2904498577 sec\n",
      "(STEP 3800) loss= 0.240718 acc= 0.92 accum_acc= 0.8986 t= 21.3443779945 sec\n",
      "(STEP 3810) loss= 0.315847 acc= 0.92 accum_acc= 0.8994 t= 21.4298899174 sec\n",
      "(STEP 3820) loss= 0.443284 acc= 0.92 accum_acc= 0.9002 t= 21.4931178093 sec\n",
      "(STEP 3830) loss= 0.462338 acc= 0.91 accum_acc= 0.9008 t= 21.5632557869 sec\n",
      "(STEP 3840) loss= 0.377123 acc= 0.9 accum_acc= 0.9011 t= 21.6022617817 sec\n",
      "(STEP 3850) loss= 0.316219 acc= 0.9 accum_acc= 0.8997 t= 21.6494438648 sec\n",
      "(STEP 3860) loss= 0.289466 acc= 0.92 accum_acc= 0.9004 t= 21.6785709858 sec\n",
      "(STEP 3870) loss= 0.356477 acc= 0.91 accum_acc= 0.8994 t= 21.7077620029 sec\n",
      "(STEP 3880) loss= 0.291587 acc= 0.92 accum_acc= 0.9017 t= 21.7387788296 sec\n",
      "(STEP 3890) loss= 0.340591 acc= 0.9 accum_acc= 0.9006 t= 21.7727940083 sec\n",
      "(STEP 3900) loss= 0.259668 acc= 0.93 accum_acc= 0.9013 t= 21.810918808 sec\n",
      "(STEP 3910) loss= 0.407698 acc= 0.89 accum_acc= 0.9012 t= 21.8511579037 sec\n",
      "(STEP 3920) loss= 0.421064 acc= 0.87 accum_acc= 0.9003 t= 21.8903570175 sec\n",
      "(STEP 3930) loss= 0.302893 acc= 0.87 accum_acc= 0.9001 t= 21.9243309498 sec\n",
      "(STEP 3940) loss= 0.313655 acc= 0.92 accum_acc= 0.8983 t= 21.9552857876 sec\n",
      "(STEP 3950) loss= 0.305396 acc= 0.92 accum_acc= 0.8998 t= 21.9870409966 sec\n",
      "(STEP 3960) loss= 0.340703 acc= 0.9 accum_acc= 0.9002 t= 22.0297279358 sec\n",
      "(STEP 3970) loss= 0.377009 acc= 0.9 accum_acc= 0.9021 t= 22.0599789619 sec\n",
      "(STEP 3980) loss= 0.344535 acc= 0.9 accum_acc= 0.902 t= 22.0905058384 sec\n",
      "(STEP 3990) loss= 0.300551 acc= 0.91 accum_acc= 0.9023 t= 22.165574789 sec\n",
      "(STEP 4000) loss= 0.483137 acc= 0.86 accum_acc= 0.9013 t= 22.2501227856 sec\n",
      "(STEP 4010) loss= 0.290824 acc= 0.91 accum_acc= 0.9022 t= 22.331291914 sec\n",
      "(STEP 4020) loss= 0.327935 acc= 0.9 accum_acc= 0.902 t= 22.4103078842 sec\n",
      "(STEP 4030) loss= 0.265036 acc= 0.93 accum_acc= 0.903 t= 22.4442420006 sec\n",
      "(STEP 4040) loss= 0.368369 acc= 0.89 accum_acc= 0.9035 t= 22.4821519852 sec\n",
      "(STEP 4050) loss= 0.344993 acc= 0.93 accum_acc= 0.9024 t= 22.578414917 sec\n",
      "(STEP 4060) loss= 0.377351 acc= 0.85 accum_acc= 0.9009 t= 22.6551728249 sec\n",
      "(STEP 4070) loss= 0.36961 acc= 0.91 accum_acc= 0.8983 t= 22.7157239914 sec\n",
      "(STEP 4080) loss= 0.411721 acc= 0.86 accum_acc= 0.8983 t= 22.7563698292 sec\n",
      "(STEP 4090) loss= 0.421572 acc= 0.91 accum_acc= 0.8994 t= 22.7872757912 sec\n",
      "(STEP 4100) loss= 0.323953 acc= 0.88 accum_acc= 0.8996 t= 22.8191308975 sec\n",
      "(STEP 4110) loss= 0.310324 acc= 0.92 accum_acc= 0.8995 t= 22.8521068096 sec\n",
      "(STEP 4120) loss= 0.253147 acc= 0.95 accum_acc= 0.8999 t= 22.8855998516 sec\n",
      "(STEP 4130) loss= 0.31373 acc= 0.9 accum_acc= 0.8986 t= 22.9153308868 sec\n",
      "(STEP 4140) loss= 0.260914 acc= 0.91 accum_acc= 0.8982 t= 22.9541478157 sec\n",
      "(STEP 4150) loss= 0.506513 acc= 0.89 accum_acc= 0.8993 t= 22.9919698238 sec\n",
      "(STEP 4160) loss= 0.535505 acc= 0.88 accum_acc= 0.8988 t= 23.0441558361 sec\n",
      "(STEP 4170) loss= 0.296265 acc= 0.91 accum_acc= 0.8993 t= 23.1367528439 sec\n",
      "(STEP 4180) loss= 0.450536 acc= 0.9 accum_acc= 0.898 t= 23.1854758263 sec\n",
      "(STEP 4190) loss= 0.227504 acc= 0.92 accum_acc= 0.8983 t= 23.2192299366 sec\n",
      "(STEP 4199) loss= 0.45471 acc= 0.88 accum_acc= 0.8985 t= 23.2574999332 sec\n",
      "EPOCH: 8\n",
      "(STEP 4200) loss= 0.30388 acc= 0.92 accum_acc= 0.8989 t= 23.5502829552 sec\n",
      "(STEP 4210) loss= 0.403945 acc= 0.93 accum_acc= 0.8987 t= 23.579818964 sec\n",
      "(STEP 4220) loss= 0.366976 acc= 0.89 accum_acc= 0.8982 t= 23.6089568138 sec\n",
      "(STEP 4230) loss= 0.262554 acc= 0.94 accum_acc= 0.8996 t= 23.642800808 sec\n",
      "(STEP 4240) loss= 0.342613 acc= 0.88 accum_acc= 0.9012 t= 23.6752598286 sec\n",
      "(STEP 4250) loss= 0.315912 acc= 0.92 accum_acc= 0.9013 t= 23.721282959 sec\n",
      "(STEP 4260) loss= 0.293458 acc= 0.94 accum_acc= 0.9024 t= 23.7647988796 sec\n",
      "(STEP 4270) loss= 0.496298 acc= 0.87 accum_acc= 0.904 t= 23.8055949211 sec\n",
      "(STEP 4280) loss= 0.46424 acc= 0.87 accum_acc= 0.9047 t= 23.8648209572 sec\n",
      "(STEP 4290) loss= 0.450159 acc= 0.82 accum_acc= 0.903 t= 23.9248588085 sec\n",
      "(STEP 4300) loss= 0.399905 acc= 0.89 accum_acc= 0.903 t= 23.9577679634 sec\n",
      "(STEP 4310) loss= 0.368715 acc= 0.88 accum_acc= 0.9023 t= 23.9918529987 sec\n",
      "(STEP 4320) loss= 0.399664 acc= 0.9 accum_acc= 0.9035 t= 24.0325939655 sec\n",
      "(STEP 4330) loss= 0.263635 acc= 0.94 accum_acc= 0.9039 t= 24.0644807816 sec\n",
      "(STEP 4340) loss= 0.431922 acc= 0.88 accum_acc= 0.9034 t= 24.0934808254 sec\n",
      "(STEP 4350) loss= 0.31207 acc= 0.91 accum_acc= 0.9033 t= 24.1290049553 sec\n",
      "(STEP 4360) loss= 0.240014 acc= 0.94 accum_acc= 0.9042 t= 24.1591668129 sec\n",
      "(STEP 4370) loss= 0.289576 acc= 0.9 accum_acc= 0.9038 t= 24.1885418892 sec\n",
      "(STEP 4380) loss= 0.612878 acc= 0.8 accum_acc= 0.9022 t= 24.2268857956 sec\n",
      "(STEP 4390) loss= 0.3067 acc= 0.89 accum_acc= 0.9018 t= 24.2641539574 sec\n",
      "(STEP 4400) loss= 0.406385 acc= 0.91 accum_acc= 0.9013 t= 24.293804884 sec\n",
      "(STEP 4410) loss= 0.347701 acc= 0.89 accum_acc= 0.9024 t= 24.323071003 sec\n",
      "(STEP 4420) loss= 0.497896 acc= 0.92 accum_acc= 0.9022 t= 24.3523609638 sec\n",
      "(STEP 4430) loss= 0.451022 acc= 0.87 accum_acc= 0.9017 t= 24.3843719959 sec\n",
      "(STEP 4440) loss= 0.490003 acc= 0.87 accum_acc= 0.9025 t= 24.4133358002 sec\n",
      "(STEP 4450) loss= 0.28346 acc= 0.93 accum_acc= 0.9032 t= 24.445953846 sec\n",
      "(STEP 4460) loss= 0.334155 acc= 0.9 accum_acc= 0.9024 t= 24.4883368015 sec\n",
      "(STEP 4470) loss= 0.409162 acc= 0.9 accum_acc= 0.9026 t= 24.5219769478 sec\n",
      "(STEP 4480) loss= 0.367906 acc= 0.9 accum_acc= 0.9033 t= 24.5520498753 sec\n",
      "(STEP 4490) loss= 0.266442 acc= 0.96 accum_acc= 0.9061 t= 24.5814669132 sec\n",
      "(STEP 4500) loss= 0.384361 acc= 0.89 accum_acc= 0.9074 t= 24.6106607914 sec\n",
      "(STEP 4510) loss= 0.301463 acc= 0.92 accum_acc= 0.9071 t= 24.6437118053 sec\n",
      "(STEP 4520) loss= 0.370694 acc= 0.9 accum_acc= 0.9067 t= 24.6790177822 sec\n",
      "(STEP 4530) loss= 0.243266 acc= 0.94 accum_acc= 0.9064 t= 24.716149807 sec\n",
      "(STEP 4540) loss= 0.321419 acc= 0.88 accum_acc= 0.9067 t= 24.7457439899 sec\n",
      "(STEP 4550) loss= 0.345105 acc= 0.88 accum_acc= 0.9059 t= 24.7748119831 sec\n",
      "(STEP 4560) loss= 0.373521 acc= 0.89 accum_acc= 0.9053 t= 24.8043239117 sec\n",
      "(STEP 4570) loss= 0.401821 acc= 0.85 accum_acc= 0.9057 t= 24.8336420059 sec\n",
      "(STEP 4580) loss= 0.392068 acc= 0.85 accum_acc= 0.9068 t= 24.8651249409 sec\n",
      "(STEP 4590) loss= 0.304747 acc= 0.93 accum_acc= 0.9057 t= 24.9015049934 sec\n",
      "(STEP 4600) loss= 0.237781 acc= 0.91 accum_acc= 0.9044 t= 24.9398407936 sec\n",
      "(STEP 4610) loss= 0.40715 acc= 0.92 accum_acc= 0.9029 t= 24.9706318378 sec\n",
      "(STEP 4620) loss= 0.445055 acc= 0.87 accum_acc= 0.9039 t= 25.0011928082 sec\n",
      "(STEP 4630) loss= 0.187759 acc= 0.95 accum_acc= 0.904 t= 25.0304429531 sec\n",
      "(STEP 4640) loss= 0.360543 acc= 0.91 accum_acc= 0.9027 t= 25.0600659847 sec\n",
      "(STEP 4650) loss= 0.339581 acc= 0.91 accum_acc= 0.9032 t= 25.0890138149 sec\n",
      "(STEP 4660) loss= 0.420149 acc= 0.9 accum_acc= 0.9025 t= 25.12281394 sec\n",
      "(STEP 4670) loss= 0.484114 acc= 0.88 accum_acc= 0.9012 t= 25.1616249084 sec\n",
      "(STEP 4680) loss= 0.353943 acc= 0.9 accum_acc= 0.9015 t= 25.1949489117 sec\n",
      "(STEP 4690) loss= 0.497788 acc= 0.85 accum_acc= 0.9004 t= 25.2238368988 sec\n",
      "(STEP 4700) loss= 0.22467 acc= 0.95 accum_acc= 0.9024 t= 25.2536199093 sec\n",
      "(STEP 4710) loss= 0.363449 acc= 0.86 accum_acc= 0.9027 t= 25.2825129032 sec\n",
      "(STEP 4720) loss= 0.210756 acc= 0.94 accum_acc= 0.9031 t= 25.3117740154 sec\n",
      "(STEP 4730) loss= 0.298013 acc= 0.9 accum_acc= 0.9034 t= 25.3449618816 sec\n",
      "(STEP 4740) loss= 0.284182 acc= 0.91 accum_acc= 0.905 t= 25.3850708008 sec\n",
      "(STEP 4750) loss= 0.286687 acc= 0.92 accum_acc= 0.9054 t= 25.4163889885 sec\n",
      "(STEP 4760) loss= 0.27732 acc= 0.92 accum_acc= 0.9055 t= 25.4459137917 sec\n",
      "(STEP 4770) loss= 0.206923 acc= 0.93 accum_acc= 0.9053 t= 25.475153923 sec\n",
      "(STEP 4780) loss= 0.267823 acc= 0.95 accum_acc= 0.9045 t= 25.5046348572 sec\n",
      "(STEP 4790) loss= 0.339078 acc= 0.91 accum_acc= 0.9049 t= 25.5338499546 sec\n",
      "(STEP 4799) loss= 0.266039 acc= 0.91 accum_acc= 0.9024 t= 25.5633859634 sec\n",
      "EPOCH: 9\n",
      "(STEP 4800) loss= 0.24091 acc= 0.93 accum_acc= 0.9022 t= 25.8835949898 sec\n",
      "(STEP 4810) loss= 0.366447 acc= 0.92 accum_acc= 0.9017 t= 25.9158909321 sec\n",
      "(STEP 4820) loss= 0.443284 acc= 0.87 accum_acc= 0.8997 t= 25.944963932 sec\n",
      "(STEP 4830) loss= 0.224064 acc= 0.96 accum_acc= 0.9 t= 25.973859787 sec\n",
      "(STEP 4840) loss= 0.367424 acc= 0.86 accum_acc= 0.8983 t= 26.0033669472 sec\n",
      "(STEP 4850) loss= 0.33927 acc= 0.92 accum_acc= 0.8991 t= 26.0324499607 sec\n",
      "(STEP 4860) loss= 0.30089 acc= 0.89 accum_acc= 0.9007 t= 26.0616738796 sec\n",
      "(STEP 4870) loss= 0.21114 acc= 0.94 accum_acc= 0.9009 t= 26.092717886 sec\n",
      "(STEP 4880) loss= 0.238796 acc= 0.92 accum_acc= 0.9025 t= 26.1371188164 sec\n",
      "(STEP 4890) loss= 0.280175 acc= 0.91 accum_acc= 0.9043 t= 26.1702618599 sec\n",
      "(STEP 4900) loss= 0.237377 acc= 0.95 accum_acc= 0.9046 t= 26.2020578384 sec\n",
      "(STEP 4910) loss= 0.444767 acc= 0.85 accum_acc= 0.9062 t= 26.2317359447 sec\n",
      "(STEP 4920) loss= 0.471015 acc= 0.85 accum_acc= 0.9063 t= 26.2615559101 sec\n",
      "(STEP 4930) loss= 0.244019 acc= 0.92 accum_acc= 0.9061 t= 26.290886879 sec\n",
      "(STEP 4940) loss= 0.512627 acc= 0.89 accum_acc= 0.9082 t= 26.3262839317 sec\n",
      "(STEP 4950) loss= 0.271838 acc= 0.9 accum_acc= 0.9074 t= 26.3640518188 sec\n",
      "(STEP 4960) loss= 0.321159 acc= 0.89 accum_acc= 0.9066 t= 26.3985998631 sec\n",
      "(STEP 4970) loss= 0.258658 acc= 0.91 accum_acc= 0.9069 t= 26.4287388325 sec\n",
      "(STEP 4980) loss= 0.350677 acc= 0.9 accum_acc= 0.9072 t= 26.4577817917 sec\n",
      "(STEP 4990) loss= 0.392787 acc= 0.92 accum_acc= 0.9058 t= 26.4870288372 sec\n",
      "(STEP 5000) loss= 0.257298 acc= 0.92 accum_acc= 0.9071 t= 26.5162229538 sec\n",
      "(STEP 5010) loss= 0.299863 acc= 0.94 accum_acc= 0.9066 t= 26.5514588356 sec\n",
      "(STEP 5020) loss= 0.308432 acc= 0.91 accum_acc= 0.9079 t= 26.5902869701 sec\n",
      "(STEP 5030) loss= 0.266189 acc= 0.96 accum_acc= 0.9074 t= 26.6200039387 sec\n",
      "(STEP 5040) loss= 0.383218 acc= 0.91 accum_acc= 0.9056 t= 26.6583278179 sec\n",
      "(STEP 5050) loss= 0.273775 acc= 0.94 accum_acc= 0.9056 t= 26.6879777908 sec\n",
      "(STEP 5060) loss= 0.340411 acc= 0.91 accum_acc= 0.9061 t= 26.7170519829 sec\n",
      "(STEP 5070) loss= 0.250829 acc= 0.9 accum_acc= 0.9082 t= 26.7464468479 sec\n",
      "(STEP 5080) loss= 0.275323 acc= 0.91 accum_acc= 0.9068 t= 26.7809209824 sec\n",
      "(STEP 5090) loss= 0.316938 acc= 0.91 accum_acc= 0.9069 t= 26.8205358982 sec\n",
      "(STEP 5100) loss= 0.316655 acc= 0.89 accum_acc= 0.906 t= 26.8527908325 sec\n",
      "(STEP 5110) loss= 0.184784 acc= 0.96 accum_acc= 0.9063 t= 26.8870577812 sec\n",
      "(STEP 5120) loss= 0.298323 acc= 0.89 accum_acc= 0.9079 t= 26.9167869091 sec\n",
      "(STEP 5130) loss= 0.339618 acc= 0.9 accum_acc= 0.9073 t= 26.9460499287 sec\n",
      "(STEP 5140) loss= 0.175534 acc= 0.97 accum_acc= 0.9082 t= 26.9757039547 sec\n",
      "(STEP 5150) loss= 0.340879 acc= 0.89 accum_acc= 0.9066 t= 27.0100150108 sec\n",
      "(STEP 5160) loss= 0.254536 acc= 0.95 accum_acc= 0.9071 t= 27.0479538441 sec\n",
      "(STEP 5170) loss= 0.432057 acc= 0.86 accum_acc= 0.9048 t= 27.0796618462 sec\n",
      "(STEP 5180) loss= 0.299542 acc= 0.92 accum_acc= 0.9057 t= 27.1089959145 sec\n",
      "(STEP 5190) loss= 0.256597 acc= 0.93 accum_acc= 0.907 t= 27.1567389965 sec\n",
      "(STEP 5200) loss= 0.289993 acc= 0.9 accum_acc= 0.908 t= 27.1859309673 sec\n",
      "(STEP 5210) loss= 0.16587 acc= 0.97 accum_acc= 0.9089 t= 27.2166109085 sec\n",
      "(STEP 5220) loss= 0.299769 acc= 0.93 accum_acc= 0.9083 t= 27.2587938309 sec\n",
      "(STEP 5230) loss= 0.271173 acc= 0.93 accum_acc= 0.9096 t= 27.2919669151 sec\n",
      "(STEP 5240) loss= 0.232217 acc= 0.95 accum_acc= 0.9105 t= 27.321505785 sec\n",
      "(STEP 5250) loss= 0.343214 acc= 0.91 accum_acc= 0.9128 t= 27.3520359993 sec\n",
      "(STEP 5260) loss= 0.462491 acc= 0.87 accum_acc= 0.9109 t= 27.3856840134 sec\n",
      "(STEP 5270) loss= 0.295036 acc= 0.91 accum_acc= 0.9118 t= 27.4160919189 sec\n",
      "(STEP 5280) loss= 0.258751 acc= 0.94 accum_acc= 0.9126 t= 27.452534914 sec\n",
      "(STEP 5290) loss= 0.417518 acc= 0.92 accum_acc= 0.9113 t= 27.4903049469 sec\n",
      "(STEP 5300) loss= 0.438464 acc= 0.88 accum_acc= 0.9113 t= 27.5201590061 sec\n",
      "(STEP 5310) loss= 0.302642 acc= 0.93 accum_acc= 0.9092 t= 27.5494809151 sec\n",
      "(STEP 5320) loss= 0.272551 acc= 0.92 accum_acc= 0.9081 t= 27.5787298679 sec\n",
      "(STEP 5330) loss= 0.243033 acc= 0.92 accum_acc= 0.9073 t= 27.6076478958 sec\n",
      "(STEP 5340) loss= 0.438793 acc= 0.88 accum_acc= 0.9058 t= 27.6414878368 sec\n",
      "(STEP 5350) loss= 0.281445 acc= 0.92 accum_acc= 0.9054 t= 27.6745798588 sec\n",
      "(STEP 5360) loss= 0.401805 acc= 0.92 accum_acc= 0.9068 t= 27.713768959 sec\n",
      "(STEP 5370) loss= 0.278297 acc= 0.93 accum_acc= 0.9059 t= 27.7437059879 sec\n",
      "(STEP 5380) loss= 0.50377 acc= 0.87 accum_acc= 0.9039 t= 27.7734417915 sec\n",
      "(STEP 5390) loss= 0.268119 acc= 0.91 accum_acc= 0.9042 t= 27.802918911 sec\n",
      "(STEP 5399) loss= 0.360715 acc= 0.9 accum_acc= 0.9041 t= 27.8292589188 sec\n",
      "EPOCH: 10\n",
      "(STEP 5400) loss= 0.305382 acc= 0.89 accum_acc= 0.9042 t= 28.1098489761 sec\n",
      "(STEP 5410) loss= 0.368291 acc= 0.9 accum_acc= 0.9031 t= 28.1430299282 sec\n",
      "(STEP 5420) loss= 0.307126 acc= 0.92 accum_acc= 0.9034 t= 28.1729149818 sec\n",
      "(STEP 5430) loss= 0.288388 acc= 0.92 accum_acc= 0.9036 t= 28.2043879032 sec\n",
      "(STEP 5440) loss= 0.34186 acc= 0.91 accum_acc= 0.9056 t= 28.233258009 sec\n",
      "(STEP 5450) loss= 0.339369 acc= 0.91 accum_acc= 0.9046 t= 28.2629089355 sec\n",
      "(STEP 5460) loss= 0.337283 acc= 0.9 accum_acc= 0.9054 t= 28.2920308113 sec\n",
      "(STEP 5470) loss= 0.316104 acc= 0.88 accum_acc= 0.9043 t= 28.3226468563 sec\n",
      "(STEP 5480) loss= 0.310985 acc= 0.92 accum_acc= 0.9061 t= 28.3583028316 sec\n",
      "(STEP 5490) loss= 0.338523 acc= 0.91 accum_acc= 0.9053 t= 28.3960659504 sec\n",
      "(STEP 5500) loss= 0.392051 acc= 0.93 accum_acc= 0.9065 t= 28.4260718822 sec\n",
      "(STEP 5510) loss= 0.293312 acc= 0.89 accum_acc= 0.908 t= 28.4549658298 sec\n",
      "(STEP 5520) loss= 0.280908 acc= 0.92 accum_acc= 0.9067 t= 28.4840888977 sec\n",
      "(STEP 5530) loss= 0.250624 acc= 0.9 accum_acc= 0.9054 t= 28.5135178566 sec\n",
      "(STEP 5540) loss= 0.280605 acc= 0.9 accum_acc= 0.9037 t= 28.5470838547 sec\n",
      "(STEP 5550) loss= 0.33164 acc= 0.89 accum_acc= 0.9059 t= 28.5839509964 sec\n",
      "(STEP 5560) loss= 0.340292 acc= 0.89 accum_acc= 0.9056 t= 28.6163289547 sec\n",
      "(STEP 5570) loss= 0.311737 acc= 0.91 accum_acc= 0.9077 t= 28.6503229141 sec\n",
      "(STEP 5580) loss= 0.427742 acc= 0.9 accum_acc= 0.9063 t= 28.6796848774 sec\n",
      "(STEP 5590) loss= 0.409939 acc= 0.87 accum_acc= 0.9071 t= 28.7089300156 sec\n",
      "(STEP 5600) loss= 0.489991 acc= 0.87 accum_acc= 0.9059 t= 28.7380290031 sec\n",
      "(STEP 5610) loss= 0.372706 acc= 0.86 accum_acc= 0.9059 t= 28.7765948772 sec\n",
      "(STEP 5620) loss= 0.387654 acc= 0.9 accum_acc= 0.9079 t= 28.8116118908 sec\n",
      "(STEP 5630) loss= 0.24717 acc= 0.94 accum_acc= 0.9097 t= 28.8467760086 sec\n",
      "(STEP 5640) loss= 0.35533 acc= 0.9 accum_acc= 0.9091 t= 28.8773908615 sec\n",
      "(STEP 5650) loss= 0.402603 acc= 0.89 accum_acc= 0.9082 t= 28.9095568657 sec\n",
      "(STEP 5660) loss= 0.359568 acc= 0.92 accum_acc= 0.9088 t= 28.9392518997 sec\n",
      "(STEP 5670) loss= 0.202308 acc= 0.95 accum_acc= 0.9077 t= 28.9686617851 sec\n",
      "(STEP 5680) loss= 0.442324 acc= 0.87 accum_acc= 0.9077 t= 29.0045979023 sec\n",
      "(STEP 5690) loss= 0.171289 acc= 0.96 accum_acc= 0.9091 t= 29.0435760021 sec\n",
      "(STEP 5700) loss= 0.313697 acc= 0.92 accum_acc= 0.9101 t= 29.0731379986 sec\n",
      "(STEP 5710) loss= 0.249144 acc= 0.93 accum_acc= 0.9103 t= 29.1025238037 sec\n",
      "(STEP 5720) loss= 0.203856 acc= 0.94 accum_acc= 0.9102 t= 29.1358737946 sec\n",
      "(STEP 5730) loss= 0.363161 acc= 0.91 accum_acc= 0.909 t= 29.1658108234 sec\n",
      "(STEP 5740) loss= 0.311271 acc= 0.91 accum_acc= 0.9103 t= 29.1975018978 sec\n",
      "(STEP 5750) loss= 0.339594 acc= 0.87 accum_acc= 0.9087 t= 29.2312338352 sec\n",
      "(STEP 5760) loss= 0.213183 acc= 0.94 accum_acc= 0.9092 t= 29.2677907944 sec\n",
      "(STEP 5770) loss= 0.249778 acc= 0.94 accum_acc= 0.911 t= 29.301817894 sec\n",
      "(STEP 5780) loss= 0.272109 acc= 0.94 accum_acc= 0.9119 t= 29.3345170021 sec\n",
      "(STEP 5790) loss= 0.2594 acc= 0.92 accum_acc= 0.9105 t= 29.3661279678 sec\n",
      "(STEP 5800) loss= 0.258186 acc= 0.94 accum_acc= 0.9095 t= 29.4042439461 sec\n",
      "(STEP 5810) loss= 0.212009 acc= 0.94 accum_acc= 0.9108 t= 29.4344189167 sec\n",
      "(STEP 5820) loss= 0.445435 acc= 0.89 accum_acc= 0.9124 t= 29.4742410183 sec\n",
      "(STEP 5830) loss= 0.468145 acc= 0.9 accum_acc= 0.9141 t= 29.5139429569 sec\n",
      "(STEP 5840) loss= 0.561297 acc= 0.87 accum_acc= 0.9136 t= 29.5438108444 sec\n",
      "(STEP 5850) loss= 0.358111 acc= 0.9 accum_acc= 0.9142 t= 29.5727908611 sec\n",
      "(STEP 5860) loss= 0.295877 acc= 0.91 accum_acc= 0.9128 t= 29.6022968292 sec\n",
      "(STEP 5870) loss= 0.279773 acc= 0.92 accum_acc= 0.9123 t= 29.6326849461 sec\n",
      "(STEP 5880) loss= 0.184442 acc= 0.96 accum_acc= 0.913 t= 29.6705789566 sec\n",
      "(STEP 5890) loss= 0.339016 acc= 0.94 accum_acc= 0.9142 t= 29.7080438137 sec\n",
      "(STEP 5900) loss= 0.234887 acc= 0.93 accum_acc= 0.9147 t= 29.7377889156 sec\n",
      "(STEP 5910) loss= 0.376222 acc= 0.89 accum_acc= 0.914 t= 29.7672898769 sec\n",
      "(STEP 5920) loss= 0.330268 acc= 0.9 accum_acc= 0.9124 t= 29.7969009876 sec\n",
      "(STEP 5930) loss= 0.177142 acc= 0.96 accum_acc= 0.913 t= 29.8259029388 sec\n",
      "(STEP 5940) loss= 0.388311 acc= 0.94 accum_acc= 0.9137 t= 29.8579759598 sec\n",
      "(STEP 5950) loss= 0.301718 acc= 0.94 accum_acc= 0.9139 t= 29.8959589005 sec\n",
      "(STEP 5960) loss= 0.277093 acc= 0.94 accum_acc= 0.9143 t= 29.942139864 sec\n",
      "(STEP 5970) loss= 0.232085 acc= 0.96 accum_acc= 0.9151 t= 29.9720308781 sec\n",
      "(STEP 5980) loss= 0.349035 acc= 0.89 accum_acc= 0.9135 t= 30.0024228096 sec\n",
      "(STEP 5990) loss= 0.282238 acc= 0.93 accum_acc= 0.9116 t= 30.031719923 sec\n",
      "(STEP 5999) loss= 0.260058 acc= 0.92 accum_acc= 0.9122 t= 30.0583548546 sec\n",
      "EPOCH: 11\n",
      "(STEP 6000) loss= 0.36772 acc= 0.9 accum_acc= 0.9119 t= 30.3489069939 sec\n",
      "(STEP 6010) loss= 0.275815 acc= 0.88 accum_acc= 0.912 t= 30.3789899349 sec\n",
      "(STEP 6020) loss= 0.2047 acc= 0.94 accum_acc= 0.9122 t= 30.4121978283 sec\n",
      "(STEP 6030) loss= 0.38014 acc= 0.92 accum_acc= 0.9116 t= 30.4420189857 sec\n",
      "(STEP 6040) loss= 0.32808 acc= 0.91 accum_acc= 0.9114 t= 30.4715919495 sec\n",
      "(STEP 6050) loss= 0.434985 acc= 0.89 accum_acc= 0.9116 t= 30.5004708767 sec\n",
      "(STEP 6060) loss= 0.285154 acc= 0.93 accum_acc= 0.911 t= 30.5290429592 sec\n",
      "(STEP 6070) loss= 0.278803 acc= 0.93 accum_acc= 0.9114 t= 30.5611050129 sec\n",
      "(STEP 6080) loss= 0.266436 acc= 0.92 accum_acc= 0.9127 t= 30.5964679718 sec\n",
      "(STEP 6090) loss= 0.198076 acc= 0.95 accum_acc= 0.9139 t= 30.6339409351 sec\n",
      "(STEP 6100) loss= 0.276047 acc= 0.93 accum_acc= 0.9125 t= 30.6659178734 sec\n",
      "(STEP 6110) loss= 0.34408 acc= 0.92 accum_acc= 0.9125 t= 30.6948518753 sec\n",
      "(STEP 6120) loss= 0.295762 acc= 0.92 accum_acc= 0.9114 t= 30.724698782 sec\n",
      "(STEP 6130) loss= 0.397276 acc= 0.91 accum_acc= 0.9119 t= 30.7536318302 sec\n",
      "(STEP 6140) loss= 0.264579 acc= 0.94 accum_acc= 0.912 t= 30.7875709534 sec\n",
      "(STEP 6150) loss= 0.345878 acc= 0.87 accum_acc= 0.9121 t= 30.8236858845 sec\n",
      "(STEP 6160) loss= 0.250089 acc= 0.92 accum_acc= 0.9125 t= 30.8618738651 sec\n",
      "(STEP 6170) loss= 0.33152 acc= 0.91 accum_acc= 0.9105 t= 30.895678997 sec\n",
      "(STEP 6180) loss= 0.314671 acc= 0.91 accum_acc= 0.9118 t= 30.9270730019 sec\n",
      "(STEP 6190) loss= 0.344102 acc= 0.88 accum_acc= 0.9113 t= 30.9569559097 sec\n",
      "(STEP 6200) loss= 0.251702 acc= 0.94 accum_acc= 0.9109 t= 30.9862008095 sec\n",
      "(STEP 6210) loss= 0.325177 acc= 0.88 accum_acc= 0.9103 t= 31.0213518143 sec\n",
      "(STEP 6220) loss= 0.224771 acc= 0.95 accum_acc= 0.9113 t= 31.0601689816 sec\n",
      "(STEP 6230) loss= 0.31599 acc= 0.93 accum_acc= 0.91 t= 31.089455843 sec\n",
      "(STEP 6240) loss= 0.353293 acc= 0.9 accum_acc= 0.91 t= 31.1299200058 sec\n",
      "(STEP 6250) loss= 0.387796 acc= 0.88 accum_acc= 0.9109 t= 31.164441824 sec\n",
      "(STEP 6260) loss= 0.449821 acc= 0.89 accum_acc= 0.9112 t= 31.1941838264 sec\n",
      "(STEP 6270) loss= 0.342555 acc= 0.88 accum_acc= 0.9126 t= 31.2241778374 sec\n",
      "(STEP 6280) loss= 0.211684 acc= 0.94 accum_acc= 0.9112 t= 31.2594809532 sec\n",
      "(STEP 6290) loss= 0.244615 acc= 0.95 accum_acc= 0.9121 t= 31.2966268063 sec\n",
      "(STEP 6300) loss= 0.218537 acc= 0.97 accum_acc= 0.9121 t= 31.3265798092 sec\n",
      "(STEP 6310) loss= 0.180193 acc= 0.96 accum_acc= 0.9131 t= 31.3570208549 sec\n",
      "(STEP 6320) loss= 0.279311 acc= 0.96 accum_acc= 0.9138 t= 31.3955469131 sec\n",
      "(STEP 6330) loss= 0.279697 acc= 0.93 accum_acc= 0.9151 t= 31.4260118008 sec\n",
      "(STEP 6340) loss= 0.275644 acc= 0.91 accum_acc= 0.9155 t= 31.4619939327 sec\n",
      "(STEP 6350) loss= 0.231787 acc= 0.94 accum_acc= 0.9149 t= 31.5012738705 sec\n",
      "(STEP 6360) loss= 0.320579 acc= 0.88 accum_acc= 0.9149 t= 31.5306630135 sec\n",
      "(STEP 6370) loss= 0.19444 acc= 0.96 accum_acc= 0.9146 t= 31.5604009628 sec\n",
      "(STEP 6380) loss= 0.284064 acc= 0.94 accum_acc= 0.9137 t= 31.5895409584 sec\n",
      "(STEP 6390) loss= 0.235872 acc= 0.9 accum_acc= 0.9124 t= 31.6186029911 sec\n",
      "(STEP 6400) loss= 0.336686 acc= 0.87 accum_acc= 0.9132 t= 31.6586749554 sec\n",
      "(STEP 6410) loss= 0.285544 acc= 0.95 accum_acc= 0.9131 t= 31.6972219944 sec\n",
      "(STEP 6420) loss= 0.209312 acc= 0.94 accum_acc= 0.913 t= 31.727036953 sec\n",
      "(STEP 6430) loss= 0.339112 acc= 0.92 accum_acc= 0.9108 t= 31.7569708824 sec\n",
      "(STEP 6440) loss= 0.551701 acc= 0.85 accum_acc= 0.9101 t= 31.78627491 sec\n",
      "(STEP 6450) loss= 0.357475 acc= 0.9 accum_acc= 0.9098 t= 31.8155238628 sec\n",
      "(STEP 6460) loss= 0.196489 acc= 0.96 accum_acc= 0.9105 t= 31.8470029831 sec\n",
      "(STEP 6470) loss= 0.317764 acc= 0.92 accum_acc= 0.9093 t= 31.8841199875 sec\n",
      "(STEP 6480) loss= 0.32811 acc= 0.92 accum_acc= 0.9104 t= 31.9241027832 sec\n",
      "(STEP 6490) loss= 0.38942 acc= 0.9 accum_acc= 0.9099 t= 31.9580798149 sec\n",
      "(STEP 6500) loss= 0.262171 acc= 0.9 accum_acc= 0.9104 t= 31.9869198799 sec\n",
      "(STEP 6510) loss= 0.216601 acc= 0.93 accum_acc= 0.9109 t= 32.0162849426 sec\n",
      "(STEP 6520) loss= 0.358088 acc= 0.92 accum_acc= 0.9097 t= 32.0454919338 sec\n",
      "(STEP 6530) loss= 0.367421 acc= 0.9 accum_acc= 0.911 t= 32.0746998787 sec\n",
      "(STEP 6540) loss= 0.396891 acc= 0.9 accum_acc= 0.9124 t= 32.1081309319 sec\n",
      "(STEP 6550) loss= 0.149231 acc= 0.95 accum_acc= 0.9133 t= 32.1560618877 sec\n",
      "(STEP 6560) loss= 0.384259 acc= 0.91 accum_acc= 0.9136 t= 32.1887688637 sec\n",
      "(STEP 6570) loss= 0.29867 acc= 0.94 accum_acc= 0.9129 t= 32.2177119255 sec\n",
      "(STEP 6580) loss= 0.188607 acc= 0.95 accum_acc= 0.9139 t= 32.2468619347 sec\n",
      "(STEP 6590) loss= 0.261774 acc= 0.94 accum_acc= 0.9151 t= 32.2759408951 sec\n",
      "(STEP 6599) loss= 0.354654 acc= 0.88 accum_acc= 0.9142 t= 32.302631855 sec\n",
      "EPOCH: 12\n",
      "(STEP 6600) loss= 0.30825 acc= 0.92 accum_acc= 0.9144 t= 32.6024107933 sec\n",
      "(STEP 6610) loss= 0.372573 acc= 0.87 accum_acc= 0.9121 t= 32.6317868233 sec\n",
      "(STEP 6620) loss= 0.243014 acc= 0.94 accum_acc= 0.9133 t= 32.6642739773 sec\n",
      "(STEP 6630) loss= 0.365758 acc= 0.9 accum_acc= 0.9144 t= 32.6933469772 sec\n",
      "(STEP 6640) loss= 0.427269 acc= 0.84 accum_acc= 0.9122 t= 32.7235689163 sec\n",
      "(STEP 6650) loss= 0.287078 acc= 0.91 accum_acc= 0.9114 t= 32.7529959679 sec\n",
      "(STEP 6660) loss= 0.413858 acc= 0.9 accum_acc= 0.9111 t= 32.7820580006 sec\n",
      "(STEP 6670) loss= 0.284549 acc= 0.92 accum_acc= 0.9137 t= 32.8130559921 sec\n",
      "(STEP 6680) loss= 0.324917 acc= 0.9 accum_acc= 0.9138 t= 32.8536789417 sec\n",
      "(STEP 6690) loss= 0.23235 acc= 0.94 accum_acc= 0.9152 t= 32.89032197 sec\n",
      "(STEP 6700) loss= 0.305068 acc= 0.9 accum_acc= 0.9146 t= 32.9215428829 sec\n",
      "(STEP 6710) loss= 0.572744 acc= 0.85 accum_acc= 0.914 t= 32.95104599 sec\n",
      "(STEP 6720) loss= 0.570636 acc= 0.81 accum_acc= 0.9126 t= 32.9803888798 sec\n",
      "(STEP 6730) loss= 0.295026 acc= 0.91 accum_acc= 0.9127 t= 33.0093917847 sec\n",
      "(STEP 6740) loss= 0.304044 acc= 0.94 accum_acc= 0.915 t= 33.043492794 sec\n",
      "(STEP 6750) loss= 0.369611 acc= 0.89 accum_acc= 0.916 t= 33.0819408894 sec\n",
      "(STEP 6760) loss= 0.270418 acc= 0.91 accum_acc= 0.9127 t= 33.1170108318 sec\n",
      "(STEP 6770) loss= 0.423502 acc= 0.89 accum_acc= 0.9112 t= 33.1517798901 sec\n",
      "(STEP 6780) loss= 0.285454 acc= 0.91 accum_acc= 0.9094 t= 33.186098814 sec\n",
      "(STEP 6790) loss= 0.342072 acc= 0.91 accum_acc= 0.9093 t= 33.2160158157 sec\n",
      "(STEP 6800) loss= 0.281933 acc= 0.94 accum_acc= 0.9118 t= 33.2458729744 sec\n",
      "(STEP 6810) loss= 0.314867 acc= 0.89 accum_acc= 0.9139 t= 33.2975168228 sec\n",
      "(STEP 6820) loss= 0.367129 acc= 0.89 accum_acc= 0.9157 t= 33.3354599476 sec\n",
      "(STEP 6830) loss= 0.22258 acc= 0.95 accum_acc= 0.9143 t= 33.3659999371 sec\n",
      "(STEP 6840) loss= 0.321102 acc= 0.88 accum_acc= 0.9139 t= 33.4022707939 sec\n",
      "(STEP 6850) loss= 0.323689 acc= 0.86 accum_acc= 0.9126 t= 33.4312288761 sec\n",
      "(STEP 6860) loss= 0.217292 acc= 0.93 accum_acc= 0.9149 t= 33.4641008377 sec\n",
      "(STEP 6870) loss= 0.362767 acc= 0.9 accum_acc= 0.9147 t= 33.5094499588 sec\n",
      "(STEP 6880) loss= 0.368931 acc= 0.89 accum_acc= 0.9157 t= 33.5404589176 sec\n",
      "(STEP 6890) loss= 0.255413 acc= 0.93 accum_acc= 0.917 t= 33.573417902 sec\n",
      "(STEP 6900) loss= 0.254911 acc= 0.96 accum_acc= 0.9175 t= 33.6031258106 sec\n",
      "(STEP 6910) loss= 0.276234 acc= 0.93 accum_acc= 0.917 t= 33.6322038174 sec\n",
      "(STEP 6920) loss= 0.329854 acc= 0.94 accum_acc= 0.9154 t= 33.6680669785 sec\n",
      "(STEP 6930) loss= 0.178351 acc= 0.96 accum_acc= 0.9162 t= 33.7145278454 sec\n",
      "(STEP 6940) loss= 0.2287 acc= 0.94 accum_acc= 0.9156 t= 33.7544488907 sec\n",
      "(STEP 6950) loss= 0.323387 acc= 0.9 accum_acc= 0.9165 t= 33.7842628956 sec\n",
      "(STEP 6960) loss= 0.280099 acc= 0.9 accum_acc= 0.9169 t= 33.8136548996 sec\n",
      "(STEP 6970) loss= 0.314552 acc= 0.94 accum_acc= 0.9189 t= 33.8452279568 sec\n",
      "(STEP 6980) loss= 0.240804 acc= 0.94 accum_acc= 0.9196 t= 33.8782098293 sec\n",
      "(STEP 6990) loss= 0.197519 acc= 0.94 accum_acc= 0.9183 t= 33.9188849926 sec\n",
      "(STEP 7000) loss= 0.274423 acc= 0.95 accum_acc= 0.9168 t= 33.9562058449 sec\n",
      "(STEP 7010) loss= 0.324274 acc= 0.91 accum_acc= 0.9178 t= 33.9855008125 sec\n",
      "(STEP 7020) loss= 0.368143 acc= 0.87 accum_acc= 0.9188 t= 34.014854908 sec\n",
      "(STEP 7030) loss= 0.236117 acc= 0.96 accum_acc= 0.9188 t= 34.0440409184 sec\n",
      "(STEP 7040) loss= 0.404714 acc= 0.89 accum_acc= 0.9176 t= 34.073682785 sec\n",
      "(STEP 7050) loss= 0.266433 acc= 0.93 accum_acc= 0.9172 t= 34.107683897 sec\n",
      "(STEP 7060) loss= 0.41092 acc= 0.89 accum_acc= 0.9166 t= 34.1513309479 sec\n",
      "(STEP 7070) loss= 0.39342 acc= 0.86 accum_acc= 0.9146 t= 34.1864459515 sec\n",
      "(STEP 7080) loss= 0.260124 acc= 0.9 accum_acc= 0.9142 t= 34.2157149315 sec\n",
      "(STEP 7090) loss= 0.25324 acc= 0.94 accum_acc= 0.9145 t= 34.2449169159 sec\n",
      "(STEP 7100) loss= 0.157538 acc= 0.96 accum_acc= 0.9149 t= 34.2741827965 sec\n",
      "(STEP 7110) loss= 0.296825 acc= 0.89 accum_acc= 0.9149 t= 34.3041357994 sec\n",
      "(STEP 7120) loss= 0.233039 acc= 0.95 accum_acc= 0.9145 t= 34.3385548592 sec\n",
      "(STEP 7130) loss= 0.340182 acc= 0.91 accum_acc= 0.9129 t= 34.3780019283 sec\n",
      "(STEP 7140) loss= 0.1933 acc= 0.93 accum_acc= 0.9155 t= 34.4121088982 sec\n",
      "(STEP 7150) loss= 0.29586 acc= 0.89 accum_acc= 0.9148 t= 34.441398859 sec\n",
      "(STEP 7160) loss= 0.280004 acc= 0.91 accum_acc= 0.9153 t= 34.4745588303 sec\n",
      "(STEP 7170) loss= 0.368792 acc= 0.87 accum_acc= 0.9156 t= 34.5040168762 sec\n",
      "(STEP 7180) loss= 0.312618 acc= 0.89 accum_acc= 0.915 t= 34.5332708359 sec\n",
      "(STEP 7190) loss= 0.260722 acc= 0.91 accum_acc= 0.9131 t= 34.5693428516 sec\n",
      "(STEP 7199) loss= 0.2591 acc= 0.9 accum_acc= 0.9114 t= 34.6061208248 sec\n",
      "EPOCH: 13\n",
      "(STEP 7200) loss= 0.31534 acc= 0.89 accum_acc= 0.9107 t= 34.8937938213 sec\n",
      "(STEP 7210) loss= 0.233531 acc= 0.96 accum_acc= 0.9106 t= 34.9280138016 sec\n",
      "(STEP 7220) loss= 0.242317 acc= 0.92 accum_acc= 0.912 t= 34.9577758312 sec\n",
      "(STEP 7230) loss= 0.304987 acc= 0.91 accum_acc= 0.9133 t= 34.9869279861 sec\n",
      "(STEP 7240) loss= 0.350778 acc= 0.93 accum_acc= 0.9105 t= 35.0161418915 sec\n",
      "(STEP 7250) loss= 0.190815 acc= 0.95 accum_acc= 0.911 t= 35.0455589294 sec\n",
      "(STEP 7260) loss= 0.241692 acc= 0.96 accum_acc= 0.9125 t= 35.074452877 sec\n",
      "(STEP 7270) loss= 0.161563 acc= 0.97 accum_acc= 0.9137 t= 35.1051588058 sec\n",
      "(STEP 7280) loss= 0.182578 acc= 0.95 accum_acc= 0.9138 t= 35.1404910088 sec\n",
      "(STEP 7290) loss= 0.283324 acc= 0.91 accum_acc= 0.916 t= 35.1841988564 sec\n",
      "(STEP 7300) loss= 0.182203 acc= 0.94 accum_acc= 0.9199 t= 35.2138168812 sec\n",
      "(STEP 7310) loss= 0.213181 acc= 0.94 accum_acc= 0.9213 t= 35.2429759502 sec\n",
      "(STEP 7320) loss= 0.4746 acc= 0.89 accum_acc= 0.9198 t= 35.2717339993 sec\n",
      "(STEP 7330) loss= 0.249413 acc= 0.93 accum_acc= 0.919 t= 35.3011598587 sec\n",
      "(STEP 7340) loss= 0.232196 acc= 0.96 accum_acc= 0.9215 t= 35.3347117901 sec\n",
      "(STEP 7350) loss= 0.241393 acc= 0.91 accum_acc= 0.9218 t= 35.3748397827 sec\n",
      "(STEP 7360) loss= 0.329608 acc= 0.89 accum_acc= 0.9198 t= 35.4082858562 sec\n",
      "(STEP 7370) loss= 0.229929 acc= 0.92 accum_acc= 0.9192 t= 35.4371647835 sec\n",
      "(STEP 7380) loss= 0.243343 acc= 0.94 accum_acc= 0.9201 t= 35.4663310051 sec\n",
      "(STEP 7390) loss= 0.292109 acc= 0.93 accum_acc= 0.9191 t= 35.4951648712 sec\n",
      "(STEP 7400) loss= 0.334286 acc= 0.92 accum_acc= 0.9174 t= 35.5243518353 sec\n",
      "(STEP 7410) loss= 0.328561 acc= 0.91 accum_acc= 0.9147 t= 35.5610699654 sec\n",
      "(STEP 7420) loss= 0.479593 acc= 0.9 accum_acc= 0.9156 t= 35.6112809181 sec\n",
      "(STEP 7430) loss= 0.340407 acc= 0.93 accum_acc= 0.9158 t= 35.6431698799 sec\n",
      "(STEP 7440) loss= 0.369188 acc= 0.93 accum_acc= 0.9146 t= 35.6789109707 sec\n",
      "(STEP 7450) loss= 0.317948 acc= 0.91 accum_acc= 0.914 t= 35.7084128857 sec\n",
      "(STEP 7460) loss= 0.370501 acc= 0.91 accum_acc= 0.9144 t= 35.7371079922 sec\n",
      "(STEP 7470) loss= 0.33413 acc= 0.93 accum_acc= 0.9149 t= 35.7690608501 sec\n",
      "(STEP 7480) loss= 0.120549 acc= 0.97 accum_acc= 0.9146 t= 35.8058547974 sec\n",
      "(STEP 7490) loss= 0.232721 acc= 0.92 accum_acc= 0.9139 t= 35.8710379601 sec\n",
      "(STEP 7500) loss= 0.257675 acc= 0.91 accum_acc= 0.9132 t= 35.9477930069 sec\n",
      "(STEP 7510) loss= 0.302337 acc= 0.93 accum_acc= 0.9159 t= 36.0043139458 sec\n",
      "(STEP 7520) loss= 0.304336 acc= 0.92 accum_acc= 0.9155 t= 36.0481917858 sec\n",
      "(STEP 7530) loss= 0.274997 acc= 0.92 accum_acc= 0.9159 t= 36.110948801 sec\n",
      "(STEP 7540) loss= 0.277923 acc= 0.89 accum_acc= 0.9162 t= 36.1461918354 sec\n",
      "(STEP 7550) loss= 0.298831 acc= 0.93 accum_acc= 0.918 t= 36.1801099777 sec\n",
      "(STEP 7560) loss= 0.236132 acc= 0.92 accum_acc= 0.9171 t= 36.218695879 sec\n",
      "(STEP 7570) loss= 0.364305 acc= 0.87 accum_acc= 0.9152 t= 36.2591149807 sec\n",
      "(STEP 7580) loss= 0.335171 acc= 0.91 accum_acc= 0.9147 t= 36.3465769291 sec\n",
      "(STEP 7590) loss= 0.255695 acc= 0.91 accum_acc= 0.9151 t= 36.3972887993 sec\n",
      "(STEP 7600) loss= 0.21376 acc= 0.95 accum_acc= 0.9166 t= 36.4533059597 sec\n",
      "(STEP 7610) loss= 0.203768 acc= 0.94 accum_acc= 0.9153 t= 36.4933857918 sec\n",
      "(STEP 7620) loss= 0.25083 acc= 0.94 accum_acc= 0.9141 t= 36.5251758099 sec\n",
      "(STEP 7630) loss= 0.217602 acc= 0.93 accum_acc= 0.915 t= 36.5560469627 sec\n",
      "(STEP 7640) loss= 0.236579 acc= 0.96 accum_acc= 0.9156 t= 36.5851669312 sec\n",
      "(STEP 7650) loss= 0.32053 acc= 0.92 accum_acc= 0.915 t= 36.6428689957 sec\n",
      "(STEP 7660) loss= 0.372211 acc= 0.92 accum_acc= 0.9165 t= 36.7035939693 sec\n",
      "(STEP 7670) loss= 0.200978 acc= 0.96 accum_acc= 0.9175 t= 36.7738268375 sec\n",
      "(STEP 7680) loss= 0.26272 acc= 0.93 accum_acc= 0.9177 t= 36.8422148228 sec\n",
      "(STEP 7690) loss= 0.269905 acc= 0.91 accum_acc= 0.9176 t= 36.8945198059 sec\n",
      "(STEP 7700) loss= 0.359256 acc= 0.9 accum_acc= 0.915 t= 36.9582779408 sec\n",
      "(STEP 7710) loss= 0.347143 acc= 0.9 accum_acc= 0.9141 t= 37.0125927925 sec\n",
      "(STEP 7720) loss= 0.344883 acc= 0.9 accum_acc= 0.916 t= 37.0477428436 sec\n",
      "(STEP 7730) loss= 0.310305 acc= 0.94 accum_acc= 0.9161 t= 37.0827360153 sec\n",
      "(STEP 7740) loss= 0.359178 acc= 0.87 accum_acc= 0.9153 t= 37.116740942 sec\n",
      "(STEP 7750) loss= 0.352406 acc= 0.89 accum_acc= 0.9159 t= 37.1592350006 sec\n",
      "(STEP 7760) loss= 0.211562 acc= 0.95 accum_acc= 0.9163 t= 37.2063059807 sec\n",
      "(STEP 7770) loss= 0.295466 acc= 0.9 accum_acc= 0.9158 t= 37.2553238869 sec\n",
      "(STEP 7780) loss= 0.360081 acc= 0.92 accum_acc= 0.9142 t= 37.2922308445 sec\n",
      "(STEP 7790) loss= 0.210197 acc= 0.94 accum_acc= 0.9156 t= 37.3533649445 sec\n",
      "(STEP 7799) loss= 0.215819 acc= 0.96 accum_acc= 0.9181 t= 37.4269897938 sec\n",
      "EPOCH: 14\n",
      "(STEP 7800) loss= 0.341264 acc= 0.89 accum_acc= 0.918 t= 37.8719789982 sec\n",
      "(STEP 7810) loss= 0.259707 acc= 0.93 accum_acc= 0.9179 t= 37.9129378796 sec\n",
      "(STEP 7820) loss= 0.207632 acc= 0.93 accum_acc= 0.9186 t= 37.9577698708 sec\n",
      "(STEP 7830) loss= 0.274313 acc= 0.92 accum_acc= 0.9173 t= 38.0240569115 sec\n",
      "(STEP 7840) loss= 0.195317 acc= 0.95 accum_acc= 0.9174 t= 38.1019318104 sec\n",
      "(STEP 7850) loss= 0.234131 acc= 0.94 accum_acc= 0.9173 t= 38.1476168633 sec\n",
      "(STEP 7860) loss= 0.231412 acc= 0.92 accum_acc= 0.9168 t= 38.2197639942 sec\n",
      "(STEP 7870) loss= 0.402539 acc= 0.87 accum_acc= 0.9164 t= 38.2641489506 sec\n",
      "(STEP 7880) loss= 0.217977 acc= 0.95 accum_acc= 0.9193 t= 38.3105728626 sec\n",
      "(STEP 7890) loss= 0.234073 acc= 0.9 accum_acc= 0.9196 t= 38.3569397926 sec\n",
      "(STEP 7900) loss= 0.240047 acc= 0.92 accum_acc= 0.9187 t= 38.4279379845 sec\n",
      "(STEP 7910) loss= 0.315479 acc= 0.9 accum_acc= 0.9197 t= 38.5064959526 sec\n",
      "(STEP 7920) loss= 0.277922 acc= 0.89 accum_acc= 0.9192 t= 38.5533368587 sec\n",
      "(STEP 7930) loss= 0.300719 acc= 0.9 accum_acc= 0.9196 t= 38.6043429375 sec\n",
      "(STEP 7940) loss= 0.148103 acc= 0.95 accum_acc= 0.9211 t= 38.6396009922 sec\n",
      "(STEP 7950) loss= 0.324894 acc= 0.89 accum_acc= 0.921 t= 38.6797449589 sec\n",
      "(STEP 7960) loss= 0.285207 acc= 0.91 accum_acc= 0.921 t= 38.7152349949 sec\n",
      "(STEP 7970) loss= 0.306722 acc= 0.94 accum_acc= 0.9223 t= 38.7983767986 sec\n",
      "(STEP 7980) loss= 0.279421 acc= 0.93 accum_acc= 0.9208 t= 38.8683958054 sec\n",
      "(STEP 7990) loss= 0.241175 acc= 0.94 accum_acc= 0.9194 t= 38.9914898872 sec\n",
      "(STEP 8000) loss= 0.253976 acc= 0.93 accum_acc= 0.9206 t= 39.025788784 sec\n",
      "(STEP 8010) loss= 0.437854 acc= 0.93 accum_acc= 0.9208 t= 39.0657219887 sec\n",
      "(STEP 8020) loss= 0.370994 acc= 0.9 accum_acc= 0.9198 t= 39.099323988 sec\n",
      "(STEP 8030) loss= 0.326067 acc= 0.91 accum_acc= 0.9196 t= 39.1286528111 sec\n",
      "(STEP 8040) loss= 0.306659 acc= 0.93 accum_acc= 0.918 t= 39.1596918106 sec\n",
      "(STEP 8050) loss= 0.317725 acc= 0.91 accum_acc= 0.9176 t= 39.1936450005 sec\n",
      "(STEP 8060) loss= 0.242341 acc= 0.91 accum_acc= 0.9186 t= 39.2242619991 sec\n",
      "(STEP 8070) loss= 0.40621 acc= 0.91 accum_acc= 0.9179 t= 39.2593019009 sec\n",
      "(STEP 8080) loss= 0.242295 acc= 0.92 accum_acc= 0.918 t= 39.2996428013 sec\n",
      "(STEP 8090) loss= 0.208892 acc= 0.94 accum_acc= 0.9189 t= 39.3784549236 sec\n",
      "(STEP 8100) loss= 0.274607 acc= 0.92 accum_acc= 0.918 t= 39.4718308449 sec\n",
      "(STEP 8110) loss= 0.245137 acc= 0.91 accum_acc= 0.9182 t= 39.5211758614 sec\n",
      "(STEP 8120) loss= 0.264782 acc= 0.91 accum_acc= 0.9193 t= 39.5629878044 sec\n",
      "(STEP 8130) loss= 0.0974111 acc= 0.99 accum_acc= 0.9209 t= 39.6066999435 sec\n",
      "(STEP 8140) loss= 0.164942 acc= 0.95 accum_acc= 0.9211 t= 39.6362149715 sec\n",
      "(STEP 8150) loss= 0.392153 acc= 0.89 accum_acc= 0.9224 t= 39.6698458195 sec\n",
      "(STEP 8160) loss= 0.443254 acc= 0.87 accum_acc= 0.9211 t= 39.7067928314 sec\n",
      "(STEP 8170) loss= 0.228232 acc= 0.94 accum_acc= 0.9229 t= 39.7450199127 sec\n",
      "(STEP 8180) loss= 0.150979 acc= 0.97 accum_acc= 0.9236 t= 39.7807478905 sec\n",
      "(STEP 8190) loss= 0.274649 acc= 0.88 accum_acc= 0.921 t= 39.8179609776 sec\n",
      "(STEP 8200) loss= 0.244814 acc= 0.92 accum_acc= 0.922 t= 39.8987939358 sec\n",
      "(STEP 8210) loss= 0.280397 acc= 0.94 accum_acc= 0.9219 t= 39.9629759789 sec\n",
      "(STEP 8220) loss= 0.118146 acc= 0.98 accum_acc= 0.9212 t= 40.0045678616 sec\n",
      "(STEP 8230) loss= 0.384993 acc= 0.87 accum_acc= 0.9192 t= 40.063615799 sec\n",
      "(STEP 8240) loss= 0.210761 acc= 0.93 accum_acc= 0.919 t= 40.0942289829 sec\n",
      "(STEP 8250) loss= 0.202114 acc= 0.97 accum_acc= 0.9182 t= 40.1235668659 sec\n",
      "(STEP 8260) loss= 0.277249 acc= 0.89 accum_acc= 0.9184 t= 40.1543328762 sec\n",
      "(STEP 8270) loss= 0.13635 acc= 0.95 accum_acc= 0.9182 t= 40.1912620068 sec\n",
      "(STEP 8280) loss= 0.293373 acc= 0.91 accum_acc= 0.9176 t= 40.2270979881 sec\n",
      "(STEP 8290) loss= 0.259237 acc= 0.91 accum_acc= 0.9181 t= 40.2621109486 sec\n",
      "(STEP 8300) loss= 0.261715 acc= 0.94 accum_acc= 0.9172 t= 40.2929148674 sec\n",
      "(STEP 8310) loss= 0.325631 acc= 0.87 accum_acc= 0.9176 t= 40.3229129314 sec\n",
      "(STEP 8320) loss= 0.196604 acc= 0.93 accum_acc= 0.916 t= 40.3533329964 sec\n",
      "(STEP 8330) loss= 0.220879 acc= 0.95 accum_acc= 0.9164 t= 40.3825719357 sec\n",
      "(STEP 8340) loss= 0.219978 acc= 0.93 accum_acc= 0.9173 t= 40.4237308502 sec\n",
      "(STEP 8350) loss= 0.382652 acc= 0.88 accum_acc= 0.9169 t= 40.4838178158 sec\n",
      "(STEP 8360) loss= 0.267711 acc= 0.92 accum_acc= 0.9162 t= 40.585411787 sec\n",
      "(STEP 8370) loss= 0.411853 acc= 0.89 accum_acc= 0.9145 t= 40.6601388454 sec\n",
      "(STEP 8380) loss= 0.350807 acc= 0.93 accum_acc= 0.9147 t= 40.7151668072 sec\n",
      "(STEP 8390) loss= 0.330454 acc= 0.89 accum_acc= 0.9149 t= 40.7577688694 sec\n",
      "(STEP 8399) loss= 0.308765 acc= 0.9 accum_acc= 0.9157 t= 40.7846858501 sec\n",
      "EPOCH: 15\n",
      "(STEP 8400) loss= 0.251857 acc= 0.9 accum_acc= 0.9153 t= 41.1282877922 sec\n",
      "(STEP 8410) loss= 0.309084 acc= 0.89 accum_acc= 0.9143 t= 41.1983599663 sec\n",
      "(STEP 8420) loss= 0.309686 acc= 0.9 accum_acc= 0.9153 t= 41.2700200081 sec\n",
      "(STEP 8430) loss= 0.164441 acc= 0.96 accum_acc= 0.9175 t= 41.3091578484 sec\n",
      "(STEP 8440) loss= 0.387153 acc= 0.88 accum_acc= 0.9155 t= 41.3418209553 sec\n",
      "(STEP 8450) loss= 0.243549 acc= 0.93 accum_acc= 0.916 t= 41.3779358864 sec\n",
      "(STEP 8460) loss= 0.516372 acc= 0.88 accum_acc= 0.9167 t= 41.4217967987 sec\n",
      "(STEP 8470) loss= 0.278943 acc= 0.92 accum_acc= 0.9178 t= 41.4524068832 sec\n",
      "(STEP 8480) loss= 0.262726 acc= 0.93 accum_acc= 0.9181 t= 41.5266180038 sec\n",
      "(STEP 8490) loss= 0.325311 acc= 0.93 accum_acc= 0.919 t= 41.595389843 sec\n",
      "(STEP 8500) loss= 0.18765 acc= 0.94 accum_acc= 0.9194 t= 41.6421229839 sec\n",
      "(STEP 8510) loss= 0.286202 acc= 0.93 accum_acc= 0.9214 t= 41.7028119564 sec\n",
      "(STEP 8520) loss= 0.273981 acc= 0.93 accum_acc= 0.9212 t= 41.7330060005 sec\n",
      "(STEP 8530) loss= 0.359992 acc= 0.89 accum_acc= 0.9202 t= 41.7625589371 sec\n",
      "(STEP 8540) loss= 0.152106 acc= 0.95 accum_acc= 0.9222 t= 41.7963759899 sec\n",
      "(STEP 8550) loss= 0.268223 acc= 0.91 accum_acc= 0.9209 t= 41.832269907 sec\n",
      "(STEP 8560) loss= 0.346064 acc= 0.9 accum_acc= 0.9227 t= 41.8791267872 sec\n",
      "(STEP 8570) loss= 0.282453 acc= 0.92 accum_acc= 0.9225 t= 41.9653859138 sec\n",
      "(STEP 8580) loss= 0.257056 acc= 0.92 accum_acc= 0.9209 t= 42.0471749306 sec\n",
      "(STEP 8590) loss= 0.460596 acc= 0.88 accum_acc= 0.9192 t= 42.0979888439 sec\n",
      "(STEP 8600) loss= 0.257454 acc= 0.91 accum_acc= 0.9183 t= 42.1391479969 sec\n",
      "(STEP 8610) loss= 0.357012 acc= 0.89 accum_acc= 0.9181 t= 42.1847548485 sec\n",
      "(STEP 8620) loss= 0.158161 acc= 0.96 accum_acc= 0.9185 t= 42.2159199715 sec\n",
      "(STEP 8630) loss= 0.331823 acc= 0.88 accum_acc= 0.9173 t= 42.2457368374 sec\n",
      "(STEP 8640) loss= 0.278705 acc= 0.92 accum_acc= 0.917 t= 42.2812747955 sec\n",
      "(STEP 8650) loss= 0.242545 acc= 0.91 accum_acc= 0.918 t= 42.3188898563 sec\n",
      "(STEP 8660) loss= 0.364594 acc= 0.9 accum_acc= 0.9162 t= 42.3522429466 sec\n",
      "(STEP 8670) loss= 0.254913 acc= 0.94 accum_acc= 0.9176 t= 42.3825848103 sec\n",
      "(STEP 8680) loss= 0.309099 acc= 0.92 accum_acc= 0.9198 t= 42.41294384 sec\n",
      "(STEP 8690) loss= 0.280584 acc= 0.91 accum_acc= 0.9215 t= 42.4485428333 sec\n",
      "(STEP 8700) loss= 0.215312 acc= 0.92 accum_acc= 0.9224 t= 42.4791018963 sec\n",
      "(STEP 8710) loss= 0.276441 acc= 0.93 accum_acc= 0.9218 t= 42.5202498436 sec\n",
      "(STEP 8720) loss= 0.212515 acc= 0.92 accum_acc= 0.9211 t= 42.6044049263 sec\n",
      "(STEP 8730) loss= 0.219468 acc= 0.93 accum_acc= 0.9218 t= 42.6955468655 sec\n",
      "(STEP 8740) loss= 0.408303 acc= 0.92 accum_acc= 0.9226 t= 42.7610728741 sec\n",
      "(STEP 8750) loss= 0.320928 acc= 0.9 accum_acc= 0.9223 t= 42.8071148396 sec\n",
      "(STEP 8760) loss= 0.320686 acc= 0.9 accum_acc= 0.923 t= 42.8715748787 sec\n",
      "(STEP 8770) loss= 0.459092 acc= 0.89 accum_acc= 0.9226 t= 42.909952879 sec\n",
      "(STEP 8780) loss= 0.399568 acc= 0.87 accum_acc= 0.9206 t= 42.9450039864 sec\n",
      "(STEP 8790) loss= 0.256208 acc= 0.93 accum_acc= 0.9206 t= 42.97783494 sec\n",
      "(STEP 8800) loss= 0.407464 acc= 0.87 accum_acc= 0.9208 t= 43.018599987 sec\n",
      "(STEP 8810) loss= 0.313246 acc= 0.92 accum_acc= 0.9211 t= 43.0863029957 sec\n",
      "(STEP 8820) loss= 0.190086 acc= 0.95 accum_acc= 0.9226 t= 43.1587967873 sec\n",
      "(STEP 8830) loss= 0.446682 acc= 0.89 accum_acc= 0.9228 t= 43.2275350094 sec\n",
      "(STEP 8840) loss= 0.367239 acc= 0.89 accum_acc= 0.9207 t= 43.2797708511 sec\n",
      "(STEP 8850) loss= 0.178713 acc= 0.95 accum_acc= 0.9207 t= 43.326392889 sec\n",
      "(STEP 8860) loss= 0.307673 acc= 0.92 accum_acc= 0.92 t= 43.3571329117 sec\n",
      "(STEP 8870) loss= 0.302521 acc= 0.9 accum_acc= 0.9204 t= 43.3865988255 sec\n",
      "(STEP 8880) loss= 0.311245 acc= 0.94 accum_acc= 0.9222 t= 43.4165058136 sec\n",
      "(STEP 8890) loss= 0.22335 acc= 0.92 accum_acc= 0.9227 t= 43.4551618099 sec\n",
      "(STEP 8900) loss= 0.355322 acc= 0.88 accum_acc= 0.9213 t= 43.4915709496 sec\n",
      "(STEP 8910) loss= 0.350961 acc= 0.93 accum_acc= 0.9211 t= 43.5283658504 sec\n",
      "(STEP 8920) loss= 0.393645 acc= 0.9 accum_acc= 0.9204 t= 43.5594758987 sec\n",
      "(STEP 8930) loss= 0.115123 acc= 0.98 accum_acc= 0.9206 t= 43.6255209446 sec\n",
      "(STEP 8940) loss= 0.288421 acc= 0.9 accum_acc= 0.9212 t= 43.69896698 sec\n",
      "(STEP 8950) loss= 0.174138 acc= 0.96 accum_acc= 0.9226 t= 43.7388768196 sec\n",
      "(STEP 8960) loss= 0.229255 acc= 0.9 accum_acc= 0.9228 t= 43.8098368645 sec\n",
      "(STEP 8970) loss= 0.548863 acc= 0.84 accum_acc= 0.9216 t= 43.8421549797 sec\n",
      "(STEP 8980) loss= 0.234134 acc= 0.92 accum_acc= 0.9209 t= 43.8736178875 sec\n",
      "(STEP 8990) loss= 0.273653 acc= 0.94 accum_acc= 0.9208 t= 43.9044039249 sec\n",
      "(STEP 8999) loss= 0.344589 acc= 0.91 accum_acc= 0.9204 t= 43.9489638805 sec\n",
      "EPOCH: 16\n",
      "(STEP 9000) loss= 0.355596 acc= 0.88 accum_acc= 0.9204 t= 44.3862178326 sec\n",
      "(STEP 9010) loss= 0.164571 acc= 0.96 accum_acc= 0.9197 t= 44.4239478111 sec\n",
      "(STEP 9020) loss= 0.443195 acc= 0.86 accum_acc= 0.9202 t= 44.4585959911 sec\n",
      "(STEP 9030) loss= 0.237374 acc= 0.95 accum_acc= 0.9202 t= 44.4895529747 sec\n",
      "(STEP 9040) loss= 0.355202 acc= 0.87 accum_acc= 0.9203 t= 44.5194618702 sec\n",
      "(STEP 9050) loss= 0.19309 acc= 0.97 accum_acc= 0.9208 t= 44.5488698483 sec\n",
      "(STEP 9060) loss= 0.221836 acc= 0.93 accum_acc= 0.9207 t= 44.5789458752 sec\n",
      "(STEP 9070) loss= 0.362696 acc= 0.9 accum_acc= 0.9213 t= 44.6124989986 sec\n",
      "(STEP 9080) loss= 0.193986 acc= 0.92 accum_acc= 0.9218 t= 44.6484148502 sec\n",
      "(STEP 9090) loss= 0.256713 acc= 0.9 accum_acc= 0.9222 t= 44.6916120052 sec\n",
      "(STEP 9100) loss= 0.233547 acc= 0.93 accum_acc= 0.9236 t= 44.7312698364 sec\n",
      "(STEP 9110) loss= 0.288301 acc= 0.94 accum_acc= 0.9258 t= 44.8003878593 sec\n",
      "(STEP 9120) loss= 0.327812 acc= 0.92 accum_acc= 0.9246 t= 44.8553109169 sec\n",
      "(STEP 9130) loss= 0.305508 acc= 0.92 accum_acc= 0.9246 t= 44.9054048061 sec\n",
      "(STEP 9140) loss= 0.221316 acc= 0.94 accum_acc= 0.9256 t= 44.9543828964 sec\n",
      "(STEP 9150) loss= 0.316083 acc= 0.89 accum_acc= 0.9237 t= 44.9843218327 sec\n",
      "(STEP 9160) loss= 0.252228 acc= 0.95 accum_acc= 0.9237 t= 45.0136578083 sec\n",
      "(STEP 9170) loss= 0.314175 acc= 0.92 accum_acc= 0.9235 t= 45.0436048508 sec\n",
      "(STEP 9180) loss= 0.219605 acc= 0.96 accum_acc= 0.9246 t= 45.0774309635 sec\n",
      "(STEP 9190) loss= 0.248009 acc= 0.92 accum_acc= 0.9244 t= 45.112528801 sec\n",
      "(STEP 9200) loss= 0.264769 acc= 0.93 accum_acc= 0.9251 t= 45.1503529549 sec\n",
      "(STEP 9210) loss= 0.22637 acc= 0.92 accum_acc= 0.9232 t= 45.185956955 sec\n",
      "(STEP 9220) loss= 0.285374 acc= 0.92 accum_acc= 0.9239 t= 45.2157769203 sec\n",
      "(STEP 9230) loss= 0.224769 acc= 0.92 accum_acc= 0.9249 t= 45.2462568283 sec\n",
      "(STEP 9240) loss= 0.33225 acc= 0.91 accum_acc= 0.9236 t= 45.2762029171 sec\n",
      "(STEP 9250) loss= 0.228227 acc= 0.95 accum_acc= 0.9245 t= 45.312735796 sec\n",
      "(STEP 9260) loss= 0.346978 acc= 0.91 accum_acc= 0.9235 t= 45.3540167809 sec\n",
      "(STEP 9270) loss= 0.255023 acc= 0.95 accum_acc= 0.9236 t= 45.3907909393 sec\n",
      "(STEP 9280) loss= 0.378244 acc= 0.89 accum_acc= 0.9199 t= 45.4374849796 sec\n",
      "(STEP 9290) loss= 0.253788 acc= 0.95 accum_acc= 0.9187 t= 45.483714819 sec\n",
      "(STEP 9300) loss= 0.240196 acc= 0.94 accum_acc= 0.9177 t= 45.5384018421 sec\n",
      "(STEP 9310) loss= 0.316593 acc= 0.89 accum_acc= 0.9171 t= 45.5763239861 sec\n",
      "(STEP 9320) loss= 0.148508 acc= 0.96 accum_acc= 0.9165 t= 45.6353189945 sec\n",
      "(STEP 9330) loss= 0.233865 acc= 0.91 accum_acc= 0.9145 t= 45.7133178711 sec\n",
      "(STEP 9340) loss= 0.165813 acc= 0.96 accum_acc= 0.9167 t= 45.7509899139 sec\n",
      "(STEP 9350) loss= 0.311363 acc= 0.92 accum_acc= 0.9148 t= 45.785804987 sec\n",
      "(STEP 9360) loss= 0.185553 acc= 0.94 accum_acc= 0.9174 t= 45.8263318539 sec\n",
      "(STEP 9370) loss= 0.149557 acc= 0.96 accum_acc= 0.9181 t= 45.8609528542 sec\n",
      "(STEP 9380) loss= 0.273102 acc= 0.95 accum_acc= 0.9197 t= 45.8941698074 sec\n",
      "(STEP 9390) loss= 0.310633 acc= 0.92 accum_acc= 0.9206 t= 45.9239778519 sec\n",
      "(STEP 9400) loss= 0.314757 acc= 0.91 accum_acc= 0.9207 t= 45.960670948 sec\n",
      "(STEP 9410) loss= 0.275417 acc= 0.92 accum_acc= 0.9216 t= 45.9981927872 sec\n",
      "(STEP 9420) loss= 0.349347 acc= 0.92 accum_acc= 0.9231 t= 46.0460410118 sec\n",
      "(STEP 9430) loss= 0.302638 acc= 0.92 accum_acc= 0.9254 t= 46.114415884 sec\n",
      "(STEP 9440) loss= 0.377662 acc= 0.88 accum_acc= 0.9219 t= 46.2008419037 sec\n",
      "(STEP 9450) loss= 0.232802 acc= 0.96 accum_acc= 0.9246 t= 46.2417678833 sec\n",
      "(STEP 9460) loss= 0.22072 acc= 0.92 accum_acc= 0.9254 t= 46.2874519825 sec\n",
      "(STEP 9470) loss= 0.253484 acc= 0.95 accum_acc= 0.9243 t= 46.3170289993 sec\n",
      "(STEP 9480) loss= 0.350766 acc= 0.89 accum_acc= 0.9234 t= 46.3522160053 sec\n",
      "(STEP 9490) loss= 0.203389 acc= 0.91 accum_acc= 0.9233 t= 46.4380338192 sec\n",
      "(STEP 9500) loss= 0.351543 acc= 0.9 accum_acc= 0.923 t= 46.4766619205 sec\n",
      "(STEP 9510) loss= 0.209937 acc= 0.94 accum_acc= 0.9227 t= 46.5581328869 sec\n",
      "(STEP 9520) loss= 0.259372 acc= 0.94 accum_acc= 0.9224 t= 46.5958018303 sec\n",
      "(STEP 9530) loss= 0.2224 acc= 0.94 accum_acc= 0.9188 t= 46.6258947849 sec\n",
      "(STEP 9540) loss= 0.210964 acc= 0.95 accum_acc= 0.9228 t= 46.6599400043 sec\n",
      "(STEP 9550) loss= 0.295823 acc= 0.92 accum_acc= 0.9217 t= 46.7011399269 sec\n",
      "(STEP 9560) loss= 0.224168 acc= 0.93 accum_acc= 0.9211 t= 46.7398679256 sec\n",
      "(STEP 9570) loss= 0.290704 acc= 0.92 accum_acc= 0.9218 t= 46.7695438862 sec\n",
      "(STEP 9580) loss= 0.501747 acc= 0.88 accum_acc= 0.922 t= 46.7991018295 sec\n",
      "(STEP 9590) loss= 0.394625 acc= 0.88 accum_acc= 0.9217 t= 46.8728899956 sec\n",
      "(STEP 9599) loss= 0.247141 acc= 0.93 accum_acc= 0.9228 t= 46.9141697884 sec\n",
      "EPOCH: 17\n",
      "(STEP 9600) loss= 0.31439 acc= 0.91 accum_acc= 0.9229 t= 47.3602199554 sec\n",
      "(STEP 9610) loss= 0.151682 acc= 0.95 accum_acc= 0.9232 t= 47.4052019119 sec\n",
      "(STEP 9620) loss= 0.188745 acc= 0.95 accum_acc= 0.924 t= 47.4459679127 sec\n",
      "(STEP 9630) loss= 0.386677 acc= 0.89 accum_acc= 0.9256 t= 47.4823257923 sec\n",
      "(STEP 9640) loss= 0.172823 acc= 0.95 accum_acc= 0.9249 t= 47.5181758404 sec\n",
      "(STEP 9650) loss= 0.293752 acc= 0.93 accum_acc= 0.9241 t= 47.5534119606 sec\n",
      "(STEP 9660) loss= 0.252527 acc= 0.92 accum_acc= 0.9223 t= 47.5975909233 sec\n",
      "(STEP 9670) loss= 0.405919 acc= 0.88 accum_acc= 0.9215 t= 47.6475439072 sec\n",
      "(STEP 9680) loss= 0.226913 acc= 0.92 accum_acc= 0.9236 t= 47.7335460186 sec\n",
      "(STEP 9690) loss= 0.277005 acc= 0.91 accum_acc= 0.9248 t= 47.830108881 sec\n",
      "(STEP 9700) loss= 0.140003 acc= 0.97 accum_acc= 0.9254 t= 47.8760788441 sec\n",
      "(STEP 9710) loss= 0.193586 acc= 0.93 accum_acc= 0.9253 t= 47.9558598995 sec\n",
      "(STEP 9720) loss= 0.130069 acc= 0.97 accum_acc= 0.9249 t= 48.0249869823 sec\n",
      "(STEP 9730) loss= 0.36284 acc= 0.89 accum_acc= 0.9246 t= 48.0758349895 sec\n",
      "(STEP 9740) loss= 0.405739 acc= 0.88 accum_acc= 0.9221 t= 48.1359519958 sec\n",
      "(STEP 9750) loss= 0.440036 acc= 0.9 accum_acc= 0.9227 t= 48.1820259094 sec\n",
      "(STEP 9760) loss= 0.178454 acc= 0.92 accum_acc= 0.9222 t= 48.2220628262 sec\n",
      "(STEP 9770) loss= 0.336269 acc= 0.9 accum_acc= 0.9224 t= 48.2582948208 sec\n",
      "(STEP 9780) loss= 0.280035 acc= 0.93 accum_acc= 0.9212 t= 48.3431768417 sec\n",
      "(STEP 9790) loss= 0.261871 acc= 0.93 accum_acc= 0.922 t= 48.388671875 sec\n",
      "(STEP 9800) loss= 0.277678 acc= 0.89 accum_acc= 0.9188 t= 48.4194879532 sec\n",
      "(STEP 9810) loss= 0.205359 acc= 0.97 accum_acc= 0.9187 t= 48.4617459774 sec\n",
      "(STEP 9820) loss= 0.342189 acc= 0.9 accum_acc= 0.9181 t= 48.4928879738 sec\n",
      "(STEP 9830) loss= 0.285743 acc= 0.91 accum_acc= 0.9181 t= 48.5328478813 sec\n",
      "(STEP 9840) loss= 0.197915 acc= 0.94 accum_acc= 0.9206 t= 48.5781869888 sec\n",
      "(STEP 9850) loss= 0.265144 acc= 0.92 accum_acc= 0.9213 t= 48.6145739555 sec\n",
      "(STEP 9860) loss= 0.201787 acc= 0.95 accum_acc= 0.9222 t= 48.6714568138 sec\n",
      "(STEP 9870) loss= 0.272997 acc= 0.89 accum_acc= 0.9233 t= 48.7343528271 sec\n",
      "(STEP 9880) loss= 0.155707 acc= 0.96 accum_acc= 0.9242 t= 48.7780098915 sec\n",
      "(STEP 9890) loss= 0.316101 acc= 0.91 accum_acc= 0.9212 t= 48.8202679157 sec\n",
      "(STEP 9900) loss= 0.232482 acc= 0.93 accum_acc= 0.9232 t= 48.864109993 sec\n",
      "(STEP 9910) loss= 0.385198 acc= 0.88 accum_acc= 0.9231 t= 48.8942239285 sec\n",
      "(STEP 9920) loss= 0.453328 acc= 0.86 accum_acc= 0.9214 t= 48.924186945 sec\n",
      "(STEP 9930) loss= 0.288866 acc= 0.92 accum_acc= 0.9222 t= 48.9609689713 sec\n",
      "(STEP 9940) loss= 0.323586 acc= 0.9 accum_acc= 0.922 t= 48.9974517822 sec\n",
      "(STEP 9950) loss= 0.241831 acc= 0.9 accum_acc= 0.9221 t= 49.0367999077 sec\n",
      "(STEP 9960) loss= 0.387565 acc= 0.93 accum_acc= 0.9242 t= 49.0834059715 sec\n",
      "(STEP 9970) loss= 0.285943 acc= 0.9 accum_acc= 0.923 t= 49.1321978569 sec\n",
      "(STEP 9980) loss= 0.299618 acc= 0.92 accum_acc= 0.9238 t= 49.1775410175 sec\n",
      "(STEP 9990) loss= 0.207756 acc= 0.93 accum_acc= 0.9257 t= 49.2251138687 sec\n",
      "(STEP 10000) loss= 0.252335 acc= 0.91 accum_acc= 0.9258 t= 49.274340868 sec\n",
      "(STEP 10010) loss= 0.161952 acc= 0.95 accum_acc= 0.9249 t= 49.3349018097 sec\n",
      "(STEP 10020) loss= 0.264826 acc= 0.94 accum_acc= 0.9253 t= 49.3748538494 sec\n",
      "(STEP 10030) loss= 0.27885 acc= 0.93 accum_acc= 0.9262 t= 49.4118390083 sec\n",
      "(STEP 10040) loss= 0.23517 acc= 0.93 accum_acc= 0.9246 t= 49.4693858624 sec\n",
      "(STEP 10050) loss= 0.264198 acc= 0.91 accum_acc= 0.9237 t= 49.5181639194 sec\n",
      "(STEP 10060) loss= 0.278851 acc= 0.9 accum_acc= 0.9224 t= 49.5695588589 sec\n",
      "(STEP 10070) loss= 0.166007 acc= 0.97 accum_acc= 0.9243 t= 49.6189517975 sec\n",
      "(STEP 10080) loss= 0.311151 acc= 0.91 accum_acc= 0.9235 t= 49.6653189659 sec\n",
      "(STEP 10090) loss= 0.270737 acc= 0.91 accum_acc= 0.9234 t= 49.7117569447 sec\n",
      "(STEP 10100) loss= 0.233676 acc= 0.91 accum_acc= 0.9237 t= 49.7865819931 sec\n",
      "(STEP 10110) loss= 0.209673 acc= 0.95 accum_acc= 0.9259 t= 49.8435029984 sec\n",
      "(STEP 10120) loss= 0.25549 acc= 0.9 accum_acc= 0.927 t= 49.9005429745 sec\n",
      "(STEP 10130) loss= 0.128 acc= 0.98 accum_acc= 0.9243 t= 49.9415559769 sec\n",
      "(STEP 10140) loss= 0.272992 acc= 0.89 accum_acc= 0.9259 t= 49.9817509651 sec\n",
      "(STEP 10150) loss= 0.305676 acc= 0.92 accum_acc= 0.9257 t= 50.0712759495 sec\n",
      "(STEP 10160) loss= 0.334685 acc= 0.92 accum_acc= 0.9259 t= 50.1077969074 sec\n",
      "(STEP 10170) loss= 0.28151 acc= 0.88 accum_acc= 0.9248 t= 50.1378369331 sec\n",
      "(STEP 10180) loss= 0.141716 acc= 0.99 accum_acc= 0.9253 t= 50.1685538292 sec\n",
      "(STEP 10190) loss= 0.29839 acc= 0.9 accum_acc= 0.9257 t= 50.2026770115 sec\n",
      "(STEP 10199) loss= 0.453452 acc= 0.89 accum_acc= 0.9244 t= 50.229134798 sec\n",
      "EPOCH: 18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c3f29e4ec5f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"EPOCH:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0macc_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAINING_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mtrain_x_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6aebd1da9d0a>\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mX_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#     if (set(Y_prime.flatten())!=set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import fftf\n",
    "import ffbn\n",
    "\n",
    "HIDDEN_1 = 100\n",
    "HIDDEN_2 = 100\n",
    "ALPHA = 0.005\n",
    "USING_BATCH_NORM = False\n",
    "if (USING_BATCH_NORM):\n",
    "    import ffbn as ff\n",
    "else: \n",
    "    import fftf as ff\n",
    "\n",
    "train_x, test_x, train_y, test_y = prepare_data(mnist)\n",
    "print \"training =>\", train_x.shape, train_y.shape\n",
    "print \"testing =>\", test_x.shape, test_y.shape\n",
    "print ff\n",
    "\n",
    "with tf.Graph().as_default():      \n",
    "    img_input = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMG_PIX])\n",
    "    label_input = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\n",
    "    model = None\n",
    "    if (USING_BATCH_NORM):\n",
    "        model = ff.inference(img_input, HIDDEN_1, HIDDEN_2, batch_norm_ver=None)\n",
    "    else:\n",
    "        model = ff.inference(img_input, HIDDEN_1, HIDDEN_2)\n",
    "    loss_f = ff.loss(model, label_input)\n",
    "    training_model = ff.training(loss_f, ALPHA)\n",
    "    eval_f = ff.evaluation(model, label_input)\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    loss_arr = []\n",
    "    eval_arr = []\n",
    "    moving_done = False\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        t0 = time.time()\n",
    "        moving_idx = 0\n",
    "        moving_avg = np.zeros(WINDOW_SIZE)\n",
    "        step = 0\n",
    "        for i in xrange(EPOCH):\n",
    "            print \"EPOCH:\", i+1\n",
    "            acc_sum = 0\n",
    "            train_x, train_y = shuffle(train_x, train_y)\n",
    "            for j in xrange(0, TRAINING_SIZE, BATCH_SIZE):\n",
    "                train_x_batch = train_x[j:j+BATCH_SIZE]\n",
    "                train_y_batch = train_y[j:j+BATCH_SIZE]\n",
    "                _, loss, correct = sess.run([training_model, loss_f, eval_f], feed_dict={\n",
    "                    img_input: train_x_batch,\n",
    "                    label_input: train_y_batch\n",
    "                })\n",
    "                \n",
    "                moving_avg[moving_idx] = correct/len(train_x_batch)\n",
    "                moving_idx += 1\n",
    "                if (moving_idx >= WINDOW_SIZE):\n",
    "                    moving_idx = 0\n",
    "                    moving_done = True\n",
    "                \n",
    "                wind_avg= moving_avg.sum()/WINDOW_SIZE\n",
    "                \n",
    "                if(j%1000)==0 or j+BATCH_SIZE == TRAINING_SIZE:\n",
    "                    print \"(STEP %s) loss= %s acc= %s accum_acc= %s t= %s sec\"%(step, loss, correct/BATCH_SIZE, wind_avg, time.time()-t0)\n",
    "                \n",
    "                if (moving_done and wind_avg >= 0.97):\n",
    "                    print \"-----------------\"\n",
    "                    print \"(STEP %s) loss= %s acc= %s accum_acc= %s t= %s sec\"%(step, loss, correct/BATCH_SIZE, wind_avg, time.time()-t0)\n",
    "                    done = True\n",
    "                    break;\n",
    "                step+=1\n",
    "                    \n",
    "            if (done):\n",
    "                break;\n",
    "        num_correct = 0\n",
    "        for k in xrange(0, TEST_SIZE, BATCH_SIZE):\n",
    "            eval_x, eval_y = test_x[k:k+BATCH_SIZE], test_y[k:k+BATCH_SIZE]\n",
    "            if (len(eval_x)!=BATCH_SIZE): \n",
    "                break\n",
    "            correct = sess.run(eval_f, feed_dict={\n",
    "                img_input: eval_x,\n",
    "                label_input: eval_y\n",
    "            })\n",
    "            num_correct += correct\n",
    "#                 print num_correct, correct\n",
    "        print \"\\tTEST ACCURACY= %s\"%(num_correct/TEST_SIZE)\n",
    "                    \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "# ds = input_data.read_data_sets(\"data\", validation_size=0)\n",
    "\n",
    "# print ds.train.epochs_completed\n",
    "# print ds.train.images.shape\n",
    "\n",
    "# print train_y[0]==ds.train.labels[1]\n",
    "# print set(ds.train.images[1]) == set(train_x[0])\n",
    "\n",
    "# plt.subplot(3,3,1)\n",
    "# plt.imshow(train_x[0].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,2)\n",
    "# plt.imshow(train_x[1].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,3)\n",
    "# plt.imshow(train_x[2].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,4)\n",
    "# plt.imshow(train_x[3].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,5)\n",
    "# plt.imshow(train_x[4].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,6)\n",
    "# plt.imshow(train_x[5].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,7)\n",
    "# plt.imshow(train_x[6].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,8)\n",
    "# plt.imshow(train_x[7].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,9)\n",
    "# plt.imshow(train_x[8].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "# # plt.subplot(1,2,2)\n",
    "# # plt.imshow(ds.train.images[3].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# # print train_y[2]\n",
    "# # print ds.train.labels[3]\n",
    "\n",
    "# print type(ds.train.labels[0])\n",
    "# print train_y[:10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
