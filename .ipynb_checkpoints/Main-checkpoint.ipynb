{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NatchaS/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import sklearn.datasets as sk_data\n",
    "\n",
    "%matplotlib inline \n",
    "mnist = fetch_mldata('MNIST original', data_home=sk_data.get_data_home())\n",
    "print mnist.data.shape\n",
    "\n",
    "def vectorize_y(Y):\n",
    "    v_y = np.zeros((Y.shape[0], max(set(Y.flatten()))+1))\n",
    "    print v_y.shape\n",
    "    for i in range(len(Y)):\n",
    "        v_y[i][Y[i]] = 1.0\n",
    "    return v_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 785)\n",
      "(26250, 784)\n",
      "(8750, 784)\n",
      "(26250, 1)\n",
      "(8750, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NatchaS/anaconda/lib/python2.7/site-packages/numpy/lib/shape_base.py:422: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  sub_arys.append(_nx.swapaxes(sary[st:end], axis, 0))\n"
     ]
    }
   ],
   "source": [
    "SPLIT_1 = 0.5\n",
    "SPLIT_2 = 0.75\n",
    "\n",
    "def shuffle(X, Y):\n",
    "    Y = np.array([Y.flatten()]).T\n",
    "    A = np.concatenate((X, Y),axis=1)\n",
    "    np.random.shuffle(A)\n",
    "    print A.shape\n",
    "    X_prime, Y_prime = np.hsplit(A, [-1])\n",
    "    if (set(Y_prime.flatten())!=set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])):\n",
    "        return shuffle(X,Y)\n",
    "    return X_prime, Y_prime\n",
    "\n",
    "\n",
    "XX, YY = shuffle(mnist.data, mnist.target)\n",
    "train_xx, test_xx = np.vsplit(XX, [len(mnist.data)*SPLIT_1])\n",
    "train_yy, test_yy = np.array_split(YY, [len(mnist.data)*SPLIT_1])\n",
    "\n",
    "train_x, test_x = np.vsplit(train_xx, [len(train_xx)*SPLIT_2])\n",
    "train_y, test_y = np.array_split(train_yy, [len(train_yy)*SPLIT_2])\n",
    "\n",
    "print train_x.shape\n",
    "print test_x.shape\n",
    "print train_y.shape\n",
    "print test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SKLearn's Support Vector Machine\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(train_x, train_y)\n",
    "# y_prime = model.predict(test_x)\n",
    "\n",
    "# pipeline = Pipeline([('pca', PCA()), ('estimator', LinearSVC())])\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'pca': [PCA()]\n",
    "#     }\n",
    "# ]\n",
    "# model = GridSearchCV(pipeline, cv=2, param_grid=param_grid)\n",
    "# model.fit(train_x, train_y)\n",
    "# y_prime = model.predict(test_x)\n",
    "\n",
    "\n",
    "pca = PCA(svd_solver='randomized',whiten=True).fit(train_x)\n",
    "pca_train_x = pca.transform(train_x)\n",
    "pca_test_x = pca.transform(test_x)\n",
    "model = LinearSVC()\n",
    "model.fit(train_x, train_y)\n",
    "y_prime = model.predict(test_x)\n",
    "\n",
    "acc = accuracy_score(y_prime, test_y)\n",
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 87.570 s\n",
      "predicting: 0.482 s\n",
      "0.946628571429\n"
     ]
    }
   ],
   "source": [
    "# Neural Network 2 Layers. \n",
    "import time\n",
    "from collections import defaultdict\n",
    "t0 = time.time()\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (784,784), activation='relu')\n",
    "mlp.fit(train_x, train_y)\n",
    "print \"training: %.3f s\"%(time.time()-t0)\n",
    "t0 = time.time()\n",
    "y_prime = mlp.predict(test_x)\n",
    "print \"predicting: %.3f s\"%(time.time()-t0)\n",
    "\n",
    "print accuracy_score(y_prime, test_y)\n",
    "\n",
    "m = defaultdict(list)\n",
    "for i in range(len(test_x)):\n",
    "    if (len(m[y_prime[i]]) < 10):\n",
    "        m[y_prime[i]].append(test_x[i])\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-1d1d379511e9>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-1d1d379511e9>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    plot.imshow(hot_v.reshape((28,28)), cmap=plot.cm.gray_r, interpolation='nearest')\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for k in m.keys(): print len(m[k])\n",
    "i = 1\n",
    "for k,v in m.iteritems():\n",
    "    for hot_v in v:\n",
    "        plot.subplot(np.ceil(20, 5, i)\n",
    "        plot.imshow(hot_v.reshape((28,28)), cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "        plot.xlabel(\"predict=%s\"%k)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(mnist)\n",
    "print mnist.data.shape\n",
    "print mnist.target.shape\n",
    "img = mnist.data[0].reshape((28,28))\n",
    "img2 = mnist.data[1].reshape((28,28))\n",
    "print img.shape\n",
    "plot.subplot(2, 3, 1)\n",
    "plot.imshow(img, cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "plot.subplot(2, 3, 2)\n",
    "plot.imshow(img, cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "plot.subplot(2, 3, 3)\n",
    "plot.imshow(img, cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "plot.subplot(2, 3, 4)\n",
    "plot.imshow(img, cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "plot.subplot(2, 3, 5)\n",
    "plot.imshow(img, cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "plot.subplot(2, 3, 6)\n",
    "plot.imshow(img, cmap=plot.cm.gray_r, interpolation='nearest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X,y = make_moons(n_samples=500, noise=0.1)\n",
    "# X,y = make_blobs(centers=2, cluster_std=0.5, n_samples=500)\n",
    "[x_train, x_test] = np.vsplit(X, [len(X)/2])\n",
    "[y_train, y_test] = np.vsplit(y.reshape(y.shape[0],1), [len(y)/2])\n",
    "K = np.hsplit(x_train, [1])\n",
    "\n",
    "X1 = [K[0][i] for i in range(len(y_train)) if y_train[i]!=0]\n",
    "X2 = [K[1][i] for i in range(len(y_train)) if y_train[i]!=0]\n",
    "\n",
    "X3 = [K[0][i] for i in range(len(y_train)) if y_train[i]==0]\n",
    "X4 = [K[1][i] for i in range(len(y_train)) if y_train[i]==0]\n",
    "\n",
    "plot.scatter(X1, X2, color='r', alpha=0.5)\n",
    "plot.scatter(X3, X4, color='b', alpha=0.5)\n",
    "\n",
    "K2 = np.hsplit(x_test, [1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import NN\n",
    "from NN import NN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from NN import shuffle\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# model.fit(x_train, y_train)\n",
    "# y_hat = model.predict(x_test)\n",
    "\n",
    "vec_y_train = vectorize_y(y_train)\n",
    "\n",
    "model = NN(2)\n",
    "model.addDense(12)\n",
    "model.addDense(12)\n",
    "model.addDense(12)\n",
    "model.addDense(12)\n",
    "model.addDense(2)\n",
    "model.summary()\n",
    "loss_arr=[]\n",
    "model.fit(x_train, vec_y_train, epoch=2000, n_minibatch=100, loss_arr=loss_arr, verbose=False)\n",
    "plot.plot(range(len(loss_arr)), loss_arr)\n",
    "print \"LOSS: \", np.mean(loss_arr[-100:])\n",
    "\n",
    "# X5 = [K2[0][i] for i in range(len(y_hat)) if y_hat[i]!=0]\n",
    "# X6 = [K2[1][i] for i in range(len(y_hat)) if y_hat[i]!=0]\n",
    "\n",
    "# X7 = [K2[0][i] for i in range(len(y_hat)) if y_hat[i]==0]\n",
    "# X8 = [K2[1][i] for i in range(len(y_hat)) if y_hat[i]==0]\n",
    "\n",
    "# plot.scatter(X5, X6, color='r', alpha=0.5)\n",
    "# plot.scatter(X7, X8, color='b', alpha=0.5)\n",
    "# plot.scatter(X1, X2, color='r', alpha=0.5)\n",
    "# plot.scatter(X3, X4, color='b', alpha=0.5)\n",
    "\n",
    "# print \"ACC:\", accuracy_score(y_hat, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = [model.predict(x_i) for x_i in x_test]\n",
    "\n",
    "X5 = [K2[0][i] for i in range(len(y_hat)) if y_hat[i]!=0]\n",
    "X6 = [K2[1][i] for i in range(len(y_hat)) if y_hat[i]!=0]\n",
    "\n",
    "X7 = [K2[0][i] for i in range(len(y_hat)) if y_hat[i]==0]\n",
    "X8 = [K2[1][i] for i in range(len(y_hat)) if y_hat[i]==0]\n",
    "\n",
    "plot.scatter(X5, X6, color='r', alpha=0.5)\n",
    "plot.scatter(X7, X8, color='b', alpha=0.5)\n",
    "plot.scatter(X1, X2, color='grey', alpha=0.5)\n",
    "plot.scatter(X3, X4, color='grey', alpha=0.5)\n",
    "\n",
    "print \"ACC:\", accuracy_score(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes = (10,10,10,2), activation='relu')\n",
    "print model\n",
    "model.fit(x_train, y_train)\n",
    "y_hat = model.predict(x_test)\n",
    "print set(y_hat)\n",
    "\n",
    "X5 = [K2[0][i] for i in range(len(y_hat)) if y_hat[i]!=0]\n",
    "X6 = [K2[1][i] for i in range(len(y_hat)) if y_hat[i]!=0]\n",
    "\n",
    "X7 = [K2[0][i] for i in range(len(y_hat)) if y_hat[i]==0]\n",
    "X8 = [K2[1][i] for i in range(len(y_hat)) if y_hat[i]==0]\n",
    "\n",
    "plot.scatter(X5, X6, color='r', alpha=0.5)\n",
    "plot.scatter(X7, X8, color='b', alpha=0.5)\n",
    "plot.scatter(X1, X2, color='grey', alpha=0.5)\n",
    "plot.scatter(X3, X4, color='grey', alpha=0.5)\n",
    "\n",
    "print \"ACC:\", accuracy_score(y_hat, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
