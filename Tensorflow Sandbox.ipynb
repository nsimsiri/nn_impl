{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_PIX: 784\n",
      "IMG_SIZE: 28\n",
      "TOTAL_SIZE: 70000\n",
      "\n",
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import sklearn.datasets as sk_data\n",
    "import math\n",
    "import time\n",
    "#d afdsf\n",
    "mnist = fetch_mldata('MNIST original', data_home=sk_data.get_data_home())\n",
    "\n",
    "IMG_PIX = mnist.data.shape[1]\n",
    "IMG_SIZE = int(math.sqrt(IMG_PIX))\n",
    "TRAINING_SIZE = 60000\n",
    "TEST_SIZE = 10000\n",
    "TOTAL_SIZE = mnist.data.shape[0]\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 100\n",
    "WINDOW_SIZE = 10000/BATCH_SIZE\n",
    "\n",
    "print \"IMG_PIX: %s\\nIMG_SIZE: %s\\nTOTAL_SIZE: %s\\n\"%(IMG_PIX, IMG_SIZE, TOTAL_SIZE)\n",
    "\n",
    "def vectorize_y(Y):\n",
    "    v_y = np.zeros((Y.shape[0], max(set(Y.flatten()))+1))\n",
    "    print v_y.shape\n",
    "    for i in range(len(Y)):\n",
    "        v_y[i][Y[i]] = 1.0\n",
    "    return v_y\n",
    "\n",
    "def shuffle(X, Y):\n",
    "    Y = np.array([Y.flatten()]).T\n",
    "    A = np.concatenate((X, Y),axis=1)\n",
    "    np.random.shuffle(A)\n",
    "    X_prime, Y_prime = np.hsplit(A, [-1])\n",
    "#     if (set(Y_prime.flatten())!=set([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])):\n",
    "#         return shuffle(X,Y)\n",
    "    Y_prime = Y_prime.reshape(Y_prime.shape[0],)\n",
    "    return X_prime, Y_prime\n",
    "\n",
    "def prepare_data(_mnist):\n",
    "    _mnist.data = _mnist.data.astype(np.float32)\n",
    "    _mnist.data = np.multiply(_mnist.data, 1.0 / 255.0)\n",
    "    _mnist.target = _mnist.target.astype(np.uint8)\n",
    "    train_xx, test_xx = np.vsplit(_mnist.data, [TRAINING_SIZE])\n",
    "    train_yy, test_yy = np.array_split(_mnist.target, [TRAINING_SIZE])\n",
    "    return train_xx, test_xx, train_yy, test_yy\n",
    "\n",
    "print type(mnist.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training => (60000, 784) (60000,)\n",
      "testing => (10000, 784) (10000,)\n",
      "<module 'fftf' from 'fftf.pyc'>\n",
      "WARNING:tensorflow:From <ipython-input-2-51f9e8ba8567>:29: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device to node 'global_step': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nAssignAdd: CPU \nConst: GPU CPU \nAssign: CPU \nIdentity: CPU \nVariableV2: CPU \n\t [[Node: global_step = VariableV2[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\n\nCaused by op u'global_step', defined at:\n  File \"/home/bladestery/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/bladestery/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-51f9e8ba8567>\", line 27, in <module>\n    training_model = ff.training(loss_f, ALPHA)\n  File \"fftf.py\", line 88, in training\n    global_step = tf.Variable(0, name='global_step', trainable=False)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/ops/variables.py\", line 226, in __init__\n    expected_shape=expected_shape)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/ops/variables.py\", line 322, in _init_from_args\n    name=name)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/ops/state_ops.py\", line 178, in variable_op_v2\n    shared_name=shared_name)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/ops/gen_state_ops.py\", line 708, in _variable_v2\n    name=name)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2402, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'global_step': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nAssignAdd: CPU \nConst: GPU CPU \nAssign: CPU \nIdentity: CPU \nVariableV2: CPU \n\t [[Node: global_step = VariableV2[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-51f9e8ba8567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmoving_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'global_step': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nAssignAdd: CPU \nConst: GPU CPU \nAssign: CPU \nIdentity: CPU \nVariableV2: CPU \n\t [[Node: global_step = VariableV2[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\n\nCaused by op u'global_step', defined at:\n  File \"/home/bladestery/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/bladestery/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/bladestery/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-51f9e8ba8567>\", line 27, in <module>\n    training_model = ff.training(loss_f, ALPHA)\n  File \"fftf.py\", line 88, in training\n    global_step = tf.Variable(0, name='global_step', trainable=False)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/ops/variables.py\", line 226, in __init__\n    expected_shape=expected_shape)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/ops/variables.py\", line 322, in _init_from_args\n    name=name)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/ops/state_ops.py\", line 178, in variable_op_v2\n    shared_name=shared_name)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/ops/gen_state_ops.py\", line 708, in _variable_v2\n    name=name)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 2402, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/bladestery/Downloads/tensorflow/_python_build/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'global_step': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nAssignAdd: CPU \nConst: GPU CPU \nAssign: CPU \nIdentity: CPU \nVariableV2: CPU \n\t [[Node: global_step = VariableV2[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import fftf\n",
    "import ffbn\n",
    "\n",
    "HIDDEN_1 = 64\n",
    "HIDDEN_2 = 64\n",
    "ALPHA = 0.5\n",
    "USING_BATCH_NORM = False\n",
    "if (USING_BATCH_NORM):\n",
    "    import ffbn as ff\n",
    "else: \n",
    "    import fftf as ff\n",
    "\n",
    "train_x, test_x, train_y, test_y = prepare_data(mnist)\n",
    "print \"training =>\", train_x.shape, train_y.shape\n",
    "print \"testing =>\", test_x.shape, test_y.shape\n",
    "print ff\n",
    "\n",
    "with tf.Graph().as_default(), tf.device('/gpu:0'):      \n",
    "    img_input = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMG_PIX])\n",
    "    label_input = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\n",
    "    model = None\n",
    "    if (USING_BATCH_NORM):\n",
    "        model = ff.inference(img_input, HIDDEN_1, HIDDEN_2, batch_norm_ver=None)\n",
    "    else:\n",
    "        model = ff.inference(img_input, HIDDEN_1, HIDDEN_2)\n",
    "    loss_f = ff.loss(model, label_input)\n",
    "    training_model = ff.training(loss_f, ALPHA)\n",
    "    eval_f = ff.evaluation(model, label_input)\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    loss_arr = []\n",
    "    eval_arr = []\n",
    "    moving_done = False\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as sess:\n",
    "        sess.run(init)\n",
    "        t0 = time.time()\n",
    "        moving_idx = 0\n",
    "        moving_avg = np.zeros(WINDOW_SIZE)\n",
    "        step = 0\n",
    "        for i in xrange(EPOCH):\n",
    "            print \"EPOCH:\", i+1\n",
    "            acc_sum = 0\n",
    "            train_x, train_y = shuffle(train_x, train_y)\n",
    "            for j in xrange(0, TRAINING_SIZE, BATCH_SIZE):\n",
    "                train_x_batch = train_x[j:j+BATCH_SIZE]\n",
    "                train_y_batch = train_y[j:j+BATCH_SIZE]\n",
    "                _, loss, correct = sess.run([training_model, loss_f, eval_f], feed_dict={\n",
    "                    img_input: train_x_batch,\n",
    "                    label_input: train_y_batch\n",
    "                })\n",
    "                \n",
    "                moving_avg[moving_idx] = correct/len(train_x_batch)\n",
    "                moving_idx += 1\n",
    "                if (moving_idx >= WINDOW_SIZE):\n",
    "                    moving_idx = 0\n",
    "                    moving_done = True\n",
    "                \n",
    "                wind_avg= moving_avg.sum()/WINDOW_SIZE\n",
    "                \n",
    "                if(j%1000)==0 or j+BATCH_SIZE == TRAINING_SIZE:\n",
    "                    print \"(STEP %s) loss= %s acc= %s accum_acc= %s t= %s sec\"%(step, loss, correct/BATCH_SIZE, wind_avg, time.time()-t0)\n",
    "                \n",
    "                if (moving_done and wind_avg >= 0.97):\n",
    "                    print \"-----------------\"\n",
    "                    print \"(STEP %s) loss= %s acc= %s accum_acc= %s t= %s sec\"%(step, loss, correct/BATCH_SIZE, wind_avg, time.time()-t0)\n",
    "                    done = True\n",
    "                    break;\n",
    "                step+=1\n",
    "                    \n",
    "            if (done):\n",
    "                break;\n",
    "        num_correct = 0\n",
    "        for k in xrange(0, TEST_SIZE, BATCH_SIZE):\n",
    "            eval_x, eval_y = test_x[k:k+BATCH_SIZE], test_y[k:k+BATCH_SIZE]\n",
    "            if (len(eval_x)!=BATCH_SIZE): \n",
    "                break\n",
    "            correct = sess.run(eval_f, feed_dict={\n",
    "                img_input: eval_x,\n",
    "                label_input: eval_y\n",
    "            })\n",
    "            num_correct += correct\n",
    "#                 print num_correct, correct\n",
    "        print \"\\tTEST ACCURACY= %s\"%(num_correct/TEST_SIZE)\n",
    "                    \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "# ds = input_data.read_data_sets(\"data\", validation_size=0)\n",
    "\n",
    "# print ds.train.epochs_completed\n",
    "# print ds.train.images.shape\n",
    "\n",
    "# print train_y[0]==ds.train.labels[1]\n",
    "# print set(ds.train.images[1]) == set(train_x[0])\n",
    "\n",
    "# plt.subplot(3,3,1)\n",
    "# plt.imshow(train_x[0].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,2)\n",
    "# plt.imshow(train_x[1].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,3)\n",
    "# plt.imshow(train_x[2].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,4)\n",
    "# plt.imshow(train_x[3].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,5)\n",
    "# plt.imshow(train_x[4].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,6)\n",
    "# plt.imshow(train_x[5].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,7)\n",
    "# plt.imshow(train_x[6].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,8)\n",
    "# plt.imshow(train_x[7].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# plt.subplot(3,3,9)\n",
    "# plt.imshow(train_x[8].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "# # plt.subplot(1,2,2)\n",
    "# # plt.imshow(ds.train.images[3].reshape((28,28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# # print train_y[2]\n",
    "# # print ds.train.labels[3]\n",
    "\n",
    "# print type(ds.train.labels[0])\n",
    "# print train_y[:10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
